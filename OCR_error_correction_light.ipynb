{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requirements once\n",
    "!pip install spacy enchant\n",
    "\n",
    "import pickle, re\n",
    "import spacy\n",
    "from spacy.cli import download as spacy_download\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1) Load your merged pickle\n",
    "with open('/Users/marencordts/Desktop/Semantic_Data_Stories/course-data-stories/merged_all_added.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# 2) Make sure spaCy German is there\n",
    "try:\n",
    "    nlp = spacy.load('de_core_news_sm')\n",
    "except OSError:\n",
    "    spacy_download('de_core_news_sm')\n",
    "    nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "# 3) Set up your spelling corrector\n",
    "corrector = pipeline(\n",
    "    task='text2text-generation',\n",
    "    model='oliverguhr/spelling-correction-german-base',\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# optional: small dictionary check fallback\n",
    "try:\n",
    "    import enchant\n",
    "    dict_de = enchant.Dict('de_DE')\n",
    "    is_valid = lambda w: dict_de.check(w)\n",
    "except Exception:\n",
    "    is_valid = lambda w: w.isalpha()\n",
    "\n",
    "# 4) Grab the first article, take its first 10 sentences\n",
    "full_text = df.loc[0, 'plainpagefulltext']\n",
    "doc = nlp(full_text)\n",
    "first_10_sents = [sent.text for sent in doc.sents][:10]\n",
    "snippet = \" \".join(first_10_sents)\n",
    "print(\"=== ORIGINAL SNIPPET ===\")\n",
    "print(snippet)\n",
    "\n",
    "# 5) Run correction only on that snippet\n",
    "def correct_text(text):\n",
    "    corrected = text\n",
    "    # find all word-tokens\n",
    "    toks = re.findall(r\"\\b\\w+\\b\", text)\n",
    "    for tok in toks:\n",
    "        # skip if looks valid\n",
    "        if is_valid(tok):\n",
    "            continue\n",
    "        # generate a correction\n",
    "        prompt = f\"Korrigiere das falsch erkannte Wort '{tok}' im deutschen Satz: \\\"{text}\\\". Gib nur das Ersatzwort zur√ºck.\"\n",
    "        out = corrector(prompt, max_length=16, num_return_sequences=1)\n",
    "        corr = out[0]['generated_text'].strip() or tok\n",
    "        # substitute globally\n",
    "        corrected = re.sub(rf\"\\b{re.escape(tok)}\\b\", corr, corrected)\n",
    "    return corrected\n",
    "\n",
    "fixed_snippet = correct_text(snippet)\n",
    "print(\"\\n=== CORRECTED SNIPPET ===\")\n",
    "print(fixed_snippet)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
