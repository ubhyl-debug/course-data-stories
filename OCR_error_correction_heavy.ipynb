{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: spacy in ./.venv/lib/python3.13/site-packages (3.8.7)\n",
      "Requirement already satisfied: enchant in ./.venv/lib/python3.13/site-packages (0.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.13/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.13/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.13/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./.venv/lib/python3.13/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.13/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.13/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.13/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.13/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.13/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.13/site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.13/site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.13/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.13/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in ./.venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./.venv/lib/python3.13/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->spacy) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ORIGINAL SNIPPET ===\n",
      "fft, M — Schwäbischer Merkllr 3 Stuttgart — Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Kevolkerungsschichten , so be- *.L t beispielsweise der Vertreter der „Newyork l’Lg« verlören in erschreckend wachsen- »em Maße jedes Vertrauen zu der -vmtssühning. Als Zeichen für die zunehmende Rmweiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JLc, daßdieHäuserdeswohlhaben- den Westens, deren Besitzer es sich hätten Wen können, ihre Wohnungen in der Stadt mit m Aufenthalt auf dem sicheren Lande zu der- lwschen, den obdachlosen Londoner« zur Verfügung Allt würden. Stärkste Erbitterung herrsche in Mterkreisen auch darüber, daß ihnen Lohn- ghzüge gemacht würden, wenn sie wegen Er- «liitunz, Hungers und Ermüdung die von ihnen verlangte Arbeit auf den gegen Bombenangriffe ungeschützten Arbeitsplätzen nicht leisten können. Die amerikanischen Beobachter berichten von z u- nehmender Trunkenheit in England.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CORRECTED SNIPPET ===\n",
      "fft, M — Schwäbischer Merkllr 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- m Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Umweiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Besitzer Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- m Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Umweiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Besitzer Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- m Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Umweiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Besitzer Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes Stuttgart — Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- m Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Umweiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Besitzer Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- m Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Umweiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Besitzer Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- m Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Umweiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Besitzer Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 'Fft, M - Schwäbischer Merkllr 3 Stuttgart - Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Bevolkerungsschichten , so be- c’tv beispielsweise der Vertreter der (New York l’Agr) verlören in erschreckend wachsen- mußem Maße jedes Vertrauen zu der -Vomtssühning. Als Zeichen für die zunehmende Reiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JL, daß die Häuser des wohlhaben- den Westen, deren Bes. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Kevolkerungsschichten , so be- *.L t beispielsweise der Vertreter der „Newyork l’Lg« verlören in erschreckend wachsen- »em Maße jedes Vertrauen zu der -vmtssühning. Als Zeichen für die zunehmende Rmweiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JLc, daßdieHäuserdeswohlhaben- den Westens, deren Besitzer es sich hätten Wen können, ihre Wohnungen in der Stadt mit m Aufenthalt auf dem sicheren Lande zu der- lwschen, den obdachlosen Londoner« zur Verfügung Allt würden. Stärkste Erbitterung herrsche in Mterkreisen auch darüber, daß ihnen Lohn- ghzüge gemacht würden, wenn sie wegen Er- «liitunz, Hungers und Ermüdung die von ihnen verlangte Arbeit auf den gegen Bombenangriffe ungeschützten Arbeitsplätzen nicht leisten können. Die amerikanischen Beobachter berichten von z u- nehmender Trunkenheit in England.\n"
     ]
    }
   ],
   "source": [
    "# install requirements once\n",
    "!pip install spacy enchant\n",
    "\n",
    "import pickle, re\n",
    "import spacy\n",
    "from spacy.cli import download as spacy_download\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1) Load your merged pickle\n",
    "with open('/Users/marencordts/Desktop/Semantic_Data_Stories/course-data-stories/merged_all_added.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# 2) Make sure spaCy German is there\n",
    "try:\n",
    "    nlp = spacy.load('de_core_news_sm')\n",
    "except OSError:\n",
    "    spacy_download('de_core_news_sm')\n",
    "    nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "# 3) Set up your spelling corrector\n",
    "corrector = pipeline(\n",
    "    task='text2text-generation',\n",
    "    model='oliverguhr/spelling-correction-german-base',\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# optional: small dictionary check fallback\n",
    "try:\n",
    "    import enchant\n",
    "    dict_de = enchant.Dict('de_DE')\n",
    "    is_valid = lambda w: dict_de.check(w)\n",
    "except Exception:\n",
    "    is_valid = lambda w: w.isalpha()\n",
    "\n",
    "# 4) Grab the first article, take its first 10 sentences\n",
    "full_text = df.loc[0, 'plainpagefulltext']\n",
    "doc = nlp(full_text)\n",
    "first_10_sents = [sent.text for sent in doc.sents][:10]\n",
    "snippet = \" \".join(first_10_sents)\n",
    "print(\"=== ORIGINAL SNIPPET ===\")\n",
    "print(snippet)\n",
    "\n",
    "# 5) Run correction only on that snippet\n",
    "def correct_text(text):\n",
    "    corrected = text\n",
    "    # find all word-tokens\n",
    "    toks = re.findall(r\"\\b\\w+\\b\", text)\n",
    "    for tok in toks:\n",
    "        # skip if looks valid\n",
    "        if is_valid(tok):\n",
    "            continue\n",
    "        # generate a correction\n",
    "        prompt = f\"Korrigiere das falsch erkannte Wort '{tok}' im deutschen Satz: \\\"{text}\\\". Gib nur das Ersatzwort zurück.\"\n",
    "        out = corrector(prompt, max_length=16, num_return_sequences=1)\n",
    "        corr = out[0]['generated_text'].strip() or tok\n",
    "        # substitute globally\n",
    "        corrected = re.sub(rf\"\\b{re.escape(tok)}\\b\", corr, corrected)\n",
    "    return corrected\n",
    "\n",
    "fixed_snippet = correct_text(snippet)\n",
    "print(\"\\n=== CORRECTED SNIPPET ===\")\n",
    "print(fixed_snippet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: spacy in ./.venv/lib/python3.13/site-packages (3.8.7)\n",
      "Requirement already satisfied: enchant in ./.venv/lib/python3.13/site-packages (0.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.13/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.13/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.13/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.13/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.13/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./.venv/lib/python3.13/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.13/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.13/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.13/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.13/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.13/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.13/site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.13/site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.13/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.13/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in ./.venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.13/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.13/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.13/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.13/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./.venv/lib/python3.13/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy enchant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: pyenchant not available or 'Dict' missing; using alphabetic fallback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marencordts/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "\n",
    "# Optional dictionary check via pyenchant or fallback to simple alpha check\n",
    "try:\n",
    "    import enchant\n",
    "    # Ensure Dict is available\n",
    "    if hasattr(enchant, 'Dict'):\n",
    "        dict_de = enchant.Dict('de_DE')\n",
    "        def is_valid_word(token):\n",
    "            return dict_de.check(token)\n",
    "    else:\n",
    "        raise ImportError(\"enchant.Dict not found\")\n",
    "except Exception:\n",
    "    print(\"Warning: pyenchant not available or 'Dict' missing; using alphabetic fallback.\")\n",
    "    def is_valid_word(token):\n",
    "        # Treat tokens without digits and only letters as valid\n",
    "        return token.isalpha()\n",
    "\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "from spacy.cli import download as spacy_download\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "with open('/Users/marencordts/Desktop/Semantic_Data_Stories/course-data-stories/merged_all_added.pkl', 'rb') as f:\n",
    "    articles = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'articles' object type: <class 'pandas.core.frame.DataFrame'>\n",
      "Length of articles: 104236\n",
      "--- Entry 0 repr ---\n",
      "{'page_id': 'UYPNVCGFNZRHE4VD4AV6LMBHODX7QDNA-FILE_0007_DDB_FULLTEXT', 'pagenumber': 7, 'publication_date': Timestamp('1940-09-19 12:00:00'), 'place_of_distribution': ['Stuttgart'], 'language': ['ger'], 'plainpagefulltext': 'fft, M — Schwäbischer Merkllr 3 Stuttgart — Donnerstag, 19. September 1940 Starke Erbitterung im Londoner Osten Zunehmende Trunkenheit als Zeichen der versagenden Widerstandskraft Kopenhagen 19. Sept. (Sonderdienst j Amerikanische Korrespondenten er- immer deutlicher die Auflösungserscheinnn- ttt in der englischen Hauptstadt. Londons untere Kevolkerungsschichten, so be- *.L t beispielsweise der Vertreter der „Newyork l’Lg« verlören in erschreckend wachsen- »em Maße jedes Vertrauen zu der -vmtssühning. Als Zeichen für die zunehmende Rmweiflung führt der Berichterstatter an, daß die in den Armuts- und Industrievierteln des Mns wohnungslos gewordene Bevölkerung immer drehender und nachdrücklicher von der Regierung JLc, daßdieHäuserdeswohlhaben- den Westens, deren Besitzer es sich hätten Wen können, ihre Wohnungen in der Stadt mit m Aufenthalt auf dem sicheren Lande zu der- lwschen, den obdachlosen Londoner« zur Verfügung Allt würden. Stärkste Erbitterung herrsche in Mterkreisen auch darüber, daß ihnen Lohn- ghzüge gemacht würden, wenn sie wegen Er- «liitunz, Hungers und Ermüdung die von ihnen verlangte Arbeit auf den gegen Bombenangriffe ungeschützten Arbeitsplätzen nicht leisten können. Die amerikanischen Beobachter berichten von z u- nehmender Trunkenheit in England. Personen beiderlei Geschlechts würden von ihr er griffen. Die Nerven hielten die unaufhörlichen Angriffe und Bombenabwürfe einfach nicht mehr aus. Sie versuchten, sich durch Alkohol über die Trostlosigkeit ihrer Lage hinwegzutäuschen. Im Gefolge der Trun- kenheit aber ereigneten sich auch immer mehr Aus- schreitungen. Sie kämen selbst in den nur mangel haft vorhandenen öffentlichen Schutzräumen zum Ausbruch. Die Behörden versuchen, diesen An zeichen der versagenden Widerstandskraft nicht nur mit dem Einsatz von Polizeikräftcn, sondern auch mit einer früheren Schkietzung der Verkaufsstätten und Schankräume zu begegnen. So erwögen znm Beispiel Liverpool «nd Manchester, die Polizei stunde für Lokale unter strengster Strafandrohung für Ueberschreitungen auf 9 Uhr abends festzusetzen. Gehässiger Wutausbruch Siuclairs Persönliche Beleidigung gegen den Reichsmarschall jg. Stockholm 19. Sept. (Sonderdienst des SMS.) Ke ernst es um die Reserven der englischen Ver- ieidigung in der Luft bestellt sein muß, konnte nicht Etlicher dokumentiert werden, als durch einen haßerfüllten Ausspruch des englischen Luftfahrt- Ministers Sinclair. Es ist eine altbekannte Mjacfje, daß der Angegriffene, wenn er Selbst- sichecheit und Kontrolle der eigenen Kräfte ver- fort, ins blinde Wüten gerät. Sie ist am Mitt- wch wieder bestätigt worden durch einen an Ge- Mgkeit nicht mehr zu überbietenden Wutaus bruch Smdlairs gegen den Reichsmarschall. Dieser Sinclair, einer der vielen, völlig unbedeutenden Erscheinungen der englischen Politikerkaste , der Mahrtminister geworden ist, obwohl er in seinem gingen Loben niemals einen Steuerknüppel in der (trab gehabt hat, geschweige denn etwas vom Flüg gen versteht, der im besten. Falle ein Flugzeug nt als Zivilpassagier von innen kennengelernt sei, dieser erbärmliche, kleine, kläffende Parla- mtarier erfrechte sich in seiner ohnmächtigen Sut zu unglaublich persönlichen Beleidigungen m den Reichsmarschall. T-er kleine Sinclair Irin eine wahre Tollwut verfallen, „wenn er ^ dem Dach seines Luftfahrtsministeriums |t*\\' meinte er, „dann befalle ihn eine wilde Ä über das Schicksal, das nun über London hereinbreche. Die Kriminellen in Berlin und Rom müssen ausgetilgt werden\". Uwd sich geradezu übertreffend, meinte dann Sinclair, „wie Herr- lich leuchte dagegen die Tätigkeit der Piloten der königlichen Luftflotte. Diese englischen Nachtpilo ten würden nicht aus unerreichbarer Höhe, son dern ungeachtet des deutschen Flakfeuers tief an greifen und ihre Bomben mit totaler Sicherheit unter dem Einsatz ihres Lebens in militärische Ziele werfen.\" Es ist sicher nicht zum ersten Male, daß ein Regierungssprecher in London die Krankenhäuser, Arbeiterwohnungen, Kinderspielplätze und Fried höfe sowie all die andern „militärischen Ziele\", die die englischen Nachtpiraten anzugreifen pflegen, als „Präzisionsarbeit\" bezeichnet. Es ist aber zum ersten Male, und dies beweist den rapiden Zer fall der englischen Führung, daß diese Behauptung mit einem so persönlichen Haßausbruch gegen den \\'in England so gefürchteten Schöpfer der deutschen Luftwaffe geschieht. Mit gercchezu schluchzen- de r Stimme wandte sich Sinclair an die eng lischen Arbeiter und flehte sie an, trotz der deut schen Bomben an ihren Maschinen zu bleiben. Jeder, auch wenn die dritte Alarmstufe gegeben würde. Aus Sinclairs Beschwerung war deut lich zu erkennen, daß insbesondere die Londoner Arbeiterschaft sich in zunehmendem Maße weigert, während der deutschen Angriffe die Arbeit aufrecht zuerhalten. Weitere Ritterkreuze für Angehörige des Heeres und der Waffe«, ff DNB. Berlin 19. Sept. Der Führer und Oberste Befehlshaber der Wehrmacht hat auf Vorschlag des Oberbefehlshabers des Heeres, Generalseldmarschall von Brauchitsch, das Ritter kreuz zum Eisernen Kreuz an folgende Angehörige des Heeres und der Waffenff-verlichen: ff -Sturm bannführer Witt, Bataillonskommandeur in einem Regiment der Waffen-ff; Hauptmann Löwe, Kompaniechef in einem Panzerregiment; ff -Obersturmführer Vogt, Zugführer in einer Aufklärungsabteilung der Waffen-ff; Oberleutnant Hippier, Führer einer Vorausabteilung; Ober- leutnaht Bethke, Kompanieführer in einem Panzerregiment; ff ° Hauptscharfnhrer Kepp» l i n g e r, Stoßtruppführer in einem Bataillon der Waffen-ff. * ff-Sturmführer Witt, im Polenfeldzug als einer der ersten mit dem EK. I ausgezeichnet, ist Kommandeur eines Bataillons der Waffen-ff. Am Abend des 27. Mai wurde fein auf dem rechten Flügel eines Regiments der Waffen-ff eingesetztes Bataillon aus der Richtung Estaires von 20 eng lischen Panzern, denen Infanterie folgte, ange griffen. Mindestens zehn schweren feindlichen Panzern gelang es, in die Stellungen des Ba taillons, das in diesem Augenblick noch keine Panzerabwehr zur Hand hatte, einzubrechen. Das Bataillon wehrte sich so fanatisch, daß es den Eng ländern nicht gelang, die Stellung zu durchstoßen. Reun feindliche Panzer blieben bewegungsunfähig vor der Front des Bataillons Beatm. Der Ba taillonskommandeur ff -Sturmbannführer Witt hat seiner Truppe, die aus Wassergraben, Hecken, Erd löchern und Kellern den Kampf gegen die feind lichen Panzer mit größter Energie führte, ein hohes Beispiel der Furchtlosigkeit und des Willens zum Durchholten gegeben. Er war die Seele des Wider standes. Das Bataillon wehrte ferner am 17. Juni einen mit weit überlegenen Kräften angesetzten, schweren \\'kindlichen Durchbruchsversuch auf dem Plateau von Langres ab, schlug die mehrere Stun den in der Nacht vom 16. zum 17. angreifenden Franzosen zum Teil in erbittertem Nahkampf zu rück und schuf damit die Voraussetzungen für die am nächsten Tage reifenden Erfolge des Regi mentes, das dabei insgesamt fast 20 000 Gefangene machen konnte. Hauptmann Löwe, bereits im Polenfeldzug als einziger Angehöriger feiner Abteilung mit dem EK. I ausgezeichnet, zeigte auch im Kriege gegen Frankreich hervorragende Tapferkeit. Er löste be sonders als Vorhutsführer einer Kampfgruppe durch seinen persönlichen Einsatz die schwierigsten Aufgaben. So brachte er mit seiner verstärkten Kompanie und einer Schützenkompanie am 17. Mai nach heftigem Straßenkamps in Origny die für den weiteren Vormarsch der Division wichtigen Fluß« und Kanalbrücken über die Oise nach Kürzestor Zeit unversehrt in deutsche Sand. Am folgenden Tage war er maßgeblich an der Gefangennahme des Stabes der IX. französischen Arme« in Le Eatelet beteiligt. Am 20. Mai wurde durch das Eingreifen seiner Kompanie der Weg durch das stark ver teidigte Doullenz erzwungen. Am 27. Mai bahnte Hausmann Löwe, wiederum Dorhutsführer einer Kampfgruppe, den Weg durch Hondeghem und Syloestre, um am 28. an der Spitze feiner Kom panie nach Vernichtung mehrerer Bunker und eng lischer Panzerkampftvagen in die Daladier-Linie einzubrechen. Hierdurch schuf er die Voraus setzungen dafür, daß sich die Division zwei Tage später mit den von Osten her vordringenden deut schen Truppen vereinigen konnte. Schwer beschädigtes U-Boot in Gibraltar ein gelaufen Aus La Linea wird gemeldet, daß ein englisches U-Boot vor einigen Tagen mit schweren Beschädi gungen in den Hafen von Gibraltar einlief, un- augenblicklich dort ausgebessert wird. Literarisches fWilhelm E h m e r. Die Kraft der Seele. Ge danken eines Deutschen im Kriege. F. Engelhorns Nachf. Adolf Spemann, Stuttgarts Ehmer hat uns etwas zu sagen als Denker. Die Berufung dazu fühlt er aus feinem Fronterlebnis im Weltkrieg und im jetzigen Krieg um Deutschlands Weltgel tung. Fuhrertum, Kameradschaft und menschliche Bewährung in größter Not sind ihm ureigenstes Erleben, und so ringen wir mit ihm um ihren Sinn im Kampf gegen feindliche Mächte und lernen den Weg erkennen, diesen Sinn bis znm Letzten zu er füllen. Gerade die grüblerischen und nachdenklichen Menschen, die viel stärker die seelischen Nöte des Krieges empfinden und daher es leicht auch zu Zweifeln in sich kommen lassen, führt er hin zu den schöpferischen Gegenkräften des Krieges, die zu ihrer Ueberwindung führen. Ein Büchlein von hohem, sittlichem Wert und von packender Wirkung. sEttore Cozzani. Das verlorene Reich. Eine Jugend am Meer. F. G. Eottafche Buchhand lung Nachfolger Stuttgarts Das Buch wirkt wie ein beglückendes Lied auf die Heimat. Wir lernen den Dichter kennen in seiner Kindheit, wie er mit Mutter und Geschwistern seine Ferien am Meer verlebt und nun in allen bunten Farben seine Abenteuer anzubringen sucht, so wie sie der Knabe einst erlebt hat Gerade dos freut einen besonders, \\'daß der reife Mann noch mit den Augen der Fu gend all das sehen kann, was er aus vergangener Zeit der Ueberlieferung für wert hält. So werden uns die Schilderungen zum eigenen Erlebnis und die eigene Jugend kommt zurück. Die Ueber- fetzung aus dem Italienischen besorgte Elise Protz: sie liest sich flott und wirkt anheimelnd: man merkt die Uebersetzung nicht. Dr. Hans Bomhoff kr Harn Roman eines Verschollenen von Paul van der Hurk aus der Wodiensduru «Bor Gericht haben Sie ausgesagt, daß Sie niemals in Afrika gewesen sind\", warf Irene ein. »Also schön — nach Afrika auszuwandern.\" Wie- kt eine Pause. „Du wirst verstehen, daß ich nicht 111 einem Land bleiben mag, wo man mich eines Nordes verdächtigt hat. Das kann mir nicht zu- Mutet werden. Besonders dann nicht, wenn ich ^ Möglichkeit habe, mich zu rehabilitieren und ^ Rücksicht auf einen Dritten von dieser Mög- \"Mt keinen Gebrauch mache. Siehst du das ein?\" sie blickte ihn mit kühlen Augen an. . Seine : \"9 e Borrede interessierte sie nicht. Sie wußte Ht, schon, worauf er hinaus wollte. „Bitte wei- weitere ist Sache der Verhandlung.\" «Du willst also auf diesem Umweg Geld er* Mfe»?\" ,/3ch leiste einen Verzicht und will dafür eine ^gmleistung.\" ■ 1 .Wie hoch?\" »Ach erwarte deine Angaben.\" «Fünfhundert?\" fragte sie zögernd. »Hast du sie bei dir?\" .^a.\" . «Das dürste reichen bis zehn Uhr. Als Beweis daß du guten Willens bist.\" »Und weiter?\" »Zehntausend!\" \"?!^habe ich nicht.\" eu n . ll 7 chter, aber in Berlin. Es dürfte dir eine L ,^\\'eit sein, sie morgen telegraphisch überwei- F lassen.\" m allen Mut zusammen. b»h,. T Sicherheit hätte ich gegen weitere Gr« Mlungsversiiche?\" \"Wein Ehrenwort.\" »geller nichts?\" kbpfi dürfte Herr Sandkaut Gelegenheit -->-eunchland unerkannt wieder zu verlassen.\" \"r? ^erde mir die Sache überlegen.\" Wt ajj a !t D \\'^ €n um zwölf also kostet es fünfhun- ®ünL°Ii net - die Handtasche und warf ihm ein 51 Banknoten zu. ’tüfl vJt schsch er sie mit der linken Hand zu- ilhr : r q 9ren ® er mit der rechten von neuem die „Ich brauche deine endgültige Zusage. Ja oder nein. Zehntausend Mark sind für dich eine Kleinig keit. Ich weih, was du hast. Wenn ich dich schröp fen wollte, würde ich das Zehnfache verlangen.\" „Sie sind sehr gütig!\" „Gütig nicht, aber bescheiden. Nur muß ich da- mit rechnen können, daß das Geld bis morgen mittag um zwölf in meinem Besitz ist. Bis mor gen um zwölf erwarte ich dich hier.\" „Ich weiß nicht, ob das möglich sein wird\", streß sie heiser hervor. „Mein Vormund . . .\" »Inzwischen wirst du ja wohl volljährig gewor den sein\", sagte er höhnisch. Aber ihr Vormund habe noch immer die Ver mögensverwaltung unter sich. Und das Geld sei fest angelegt. „Ich weiß\", sagte er, „in Hypotheken und Pa- Pieren. Papiere lassen sich beleihen.\" Dann gab er ihr genaue Anweisungen, welche Schritte zu unternehmen seien. „Also?\" Fünf Minuten später verließ sie das Haus. Von fern her schlug es zehn Uhr. Entschlossenen Schrit tes strebte sie ben spärlich beleuchteten Straßen zu. Sie mußte jetzt handeln, so schnell wie möglich handeln. Jede Minute war kostbar. Zehntausend Mark bis morgen mittag um zwölf. „Martin.\" Sie zuckte zusammen. Obwohl sie es selbst ge wesen war, die seinen Namen geflüstert \\'hatte. War er wirklich ein Mörder? X. „Die Aufgabe, einen andern zu beobachten, zu „beschatten\" wie es in der Sprache der Polizei heißt, ist nicht so einfach, wie der Laie es sich im allgemeinen vorstellt. Bei dieser absonderlichen Tätigkeit, die sehr viel Ausdauer, Umsicht und Ge schicklichkeit erfordert, kommt es nicht nur daraus an, das Objekt ständig im Auge zu behalten, son dern der Detektiv hat auch dafür zu sorgen, daß er selbst unerkannt bleibt und daß das Objekt auf keinen Fall bemerkt, daß es beobachtet wird. Des halb muß der Detektiv bestrebt sein, sich der Um gebung, in der er arbeitet, so viel wie möglich an zupassen. Weder seine Kleidung, noch seine Haltung oder Ausdrucksweise dürfen auffallen. Und je un auffälliger er sich in dem jeweiligen Milieu zu be wegen weiß, desto größer ist die Aussicht, daß seine Arbeit mit Erfolg gekrönt wird . . .\" Mit diesen Worten hatte Poldi Finkenbusch eine neue Aufsatzreihe eingeleitet, die er unter dem Titel „Die unsichtbaren Helfer\" zu veröffentlichen beabsichtigte. Die Arbeit zeugte, soweit es sich um die Theorie handelte, von einer umfassenden Sach kenntnis, und der unbefangene Leser konnte sogar den Eindruck gewinnen, sie entstamme der Feder eines erfahrenen Kriminalisten. Zu seiner Ueberraschung sollte Poldi erfahren, daß es mit der Praxis aber doch etwas anders bestellt war. „Sehen Sie, Mr. Listen, da vorn links sitzt der junge Mann.\" Einer der Detektive im Gefolge des Maharadschas, ein eleganter älterer Herr, den man ohne weiteres für einen vermögenden Welten bummler halten konnte, wies mit einem leichten Blick auf Poldi, dessen Aufmerksamkeit durch das Eintreten einiger jungen SDameit gerade abgelenkt wurde. „Er hat sich in auffälliger Weise nach Ihnen er kundigt\", erläuterte der Detektiv, „und nun sitzt er schon Stunde um Stunde hier in der Halle. Sein Name ist Leopold Finkenbusch, sein Beruf Reporter. Als solchen gibt er sich jedenfalls aus. Kennen Sie den Herrn vielleicht, Mr. Listen? Wir behalten ihn natürlich scharf im Auge.\" „Ich möchte ihn sprechen\", entschied Mr. Listen nach kurzer Ueberlegunq. „Vielleicht hier im klei nen Konversationszimmer.\" Wenige Augenblicke später kam ein Page zu Poldi. „Herr Finkenbusch?\" „Jawohl.\" „Sie werden im kleinen Konversationszimmer erwartet.\" „Von wem?\" Der Page zeigte ein Lächeln, aus dem man alles und nichts entnehmen konnte. „Sie wüßten Be scheid.\" Poldi folgte ihm. Sobald er das Konversationszimmer betreten hatte, schloß der Page die Tür hinter ihm. Für einen kurzen Augenblick hatte Poldi das beschämende Gefühl, seiner Ausgabe nicht gewachsen zu sein. Tenn. über die Lage, in der er sich be fand, war er sich nicht im unklaren. Er war er, tappt worden. Listen, den er unauffällig beobach ten wollte, hatte diese Absicht offenbar durchschaut. Kaum anzunehmen, daß er ihn zu einer Unter- redung gebeten hatte, um über das Wetter mit ihm zu plaudern. Vorauszusehen war vielmehr, daß er Aufklärung verlangen würde. Es war eine Lage, toie sie peinlicher gar nicht sein konnte, und in der sich Poldi nicht nur einer gründlichen Niederlage, sondern auch der Lächerlichkeit preisgegeben sah. Listen begrüßte ihn mit korrekter, aber kühler Höflichkeit. „Sie sind Herr Finkenbusch, nicht wahr?\" Poldi heuchelte Erstaunen. „Jawohl.\" „Anthony Listen — in Diensten Seiner Durch laucht des Maharadschas von Patiala. Wie ich höre, wollten Sie mich gern sprechen.\" Poldi bewies genügend Geistesgegenwart. „Es freut mich sehr, Sie kennen zu lernen, Herr Listen.\" Ohne Zögern streckte er zur Begrüßung die Hand aus. „Ich bin nämlich Berichterstatter\", fuhr der er- tappte Amateurdetektiv im Plauderton fort. „Und ich sitze nur hier, um -die günstige Gelegenheit ab zuwarten, Seine Durchlaucht um ein Interview zu bittxn. Ich hoffe sehr, daß Sie mir gestatten wer den, Ihre liebenswürdige Vermittlung hierzu in Anspruch zu nehmen.\" ‘ Die Ausrede war gefunden und Poldi fühlte sich um viel Grade behaglicher. Mit einer kurzen Handbewegung forderte Listen ihn auf, Platz zu nehmen. Dabei streifte er ihn mit einem mißtrauischen Blick. „Woher kannten Sie eigentlich meinen Namen?\" Es klang so un- verbindlich tote_bet einem Verhör. „Man hat mir gesagt, Sie hätten sich bei verschiedenen Hotel- angestellten nach mir erkundigt.\" (Fortsetzung folgt.) -<=£=> aao — bb — eeeeeeeeeeee — f — 8 0 8 h h — t t i i — k — II — nnnnn -o-rrrrrr-sss-tttt-u Borstehende Buchstaben sind derart in die leeren Felder des Gitters zu ordnen, daß sich Wörter nachstehender Bedeutung ergeben: Senkrecht: L Tätigkeit. 2. Würzpflanze. 3. Augenwasser. 4. Unglück. 6. Ehefrau 6. Teil der Hand. Waagerecht: 7. Stadt im Bezirk Wiesbaden, 8. Teil der Sudeten. Auflösung des Rätsels in Nr. 218: .Dem Ver dienste feine Krone.\" ', 'paper_title': 'Schwäbischer Merkur : mit Schwäbischer Kronik und Handelszeitung : Süddeutsche Zeitung'}\n",
      "\n",
      "--- Entry 1 repr ---\n",
      "{'page_id': '5HNZ7CKJA23HRQVLH775UJINWQOLPLIT-FILE_0002_DDB_FULLTEXT', 'pagenumber': 2, 'publication_date': Timestamp('1940-09-26 12:00:00'), 'place_of_distribution': ['Stuttgart'], 'language': ['ger'], 'plainpagefulltext': 'Nr. 226 — Schwäbischer Merkm Stuttgart — Donnerstag, 26. September 1940 des Staates für wichtige Aufgaben, wie di« Kulturarbeit, allzu stark eingeschnürt wur den. Daß es Salazar gelungen ist, im Laufe der zwölf Jahre, in denen er das Finanzministerium innehatte, die riesige Staatsschuld Portugals (sie hatte sich seit der Jahrhundertwende verfunfund- siebzigfacht) nicht nur auszugleichen, sondern Portugal noch auf eine schmale, aber gesunde Ueberschußmirtschaft zu stellen, ist eine Leistung, die in der ganzen Welt offene Bewunderung und Beachtung hervorgerufen hat. Wenn Salazar, der seit der Uebernahme der Gesamtregierung vor acht Jahren als Regierungschef, Kriegs- und Außenminister zum eigentlichen Lenker des Lan des geworden ist, nunmehr das Finanzministerium abgibt, so bedeutet dies, daß r seine Aufgabe der Sanierung der zerrütteten portugiesischen Fi nanzen als beendet anficht. Portugal hat in der Tat heute eine finanzielle Grundmauerung erreicht, von der ein neues Abgleiten in eine alarmierende Defizitwirtschaft unwahrscheinlich bleibt. Salazar verläßt das Finanzministerium mit einem Haushaltvoranschlag für das Nechnungs- -ahr 1940, der trotz der unverkennbaren Rück wirkungen des Krieges in Europa noch einen Ueberschuß zeigt. Man hat Dr. Antonio de Oliveira Salazar Portugals schweigenden Diktator ge nannt. Diese Bezeichnung ist zutreffend. Er vermeidet es peinlich, sich in das Rampenlicht der Oefsentlichkeit zu stellen. Selbst bei offiziellen Staatsangelegenheiten sieht man ihn selten. Des- fcntliche Reden halten, ist ihm verhaßt, und man kann die grundlegenden Ansprachen über die Struktur des neuen Portugal an den Fingern einer Hand abzählen, die Salazar in der Dessen!- lichkeit und vor dem Mikrophon gehalten hat. Dennoch aber spürt man seine erneuernde Arbeit auf Schritt und Tritt. Salazar, der bäuerliche, unpolitische Professor aus der Provinz, wirkt gleichsam auS dem Hintergrund und lehrt seine Mitarbeiter, mit Gründlichkeit, Mechodik, ohne Ueberstürzung und unter ständiger Obenansetzung der höchsten Gemeinschaftsinter essen zu arbeiten. ES gibt nur wenige Männer und Frauen in Portugal, die den allmächtigen, aber zurückgezogenen Diktator persönlich gesehen haben. Die meisten reden von ihm und von fei ner Arbeit, ohne ihn selbst zu kennen. Seit Sa lazar die politische Bühne Portugals betrat, hat das Land nach langen Jahrzehnten der Erschütte rung wieder Ruhe gefunden. Der endlose ent- nervende Parteienhader ist mit der Beseitigung der Parteien verschwunden, die politischen Intri gen und Verschwörungen sind von der allzeit wachen Polizei deS neuen portugiesischen Staates erstickt worden, und daS größte Uebel, die einst in Portugal so mächtigen Freimaurerlogen und G e h e i m g e s e l l s ch a f t e n, sind Ber euten und aufgelöst worden. Eine neue korporative Ordnung ist eingeleitet und der soziale Fortschritt im Lande in langsamem, aber ständi gem Fluß. Die Bevölkerung hat die Segnungen des neuen Regimes in Portugal auf fast allen Gebieten zu spüren bekommen, und auS dem «inst zerrütteten Lande ist heute gleichsam eine fried liche, innerlich gefestigte Insel geworden. Diese Entwicklung ist ohne Zweifel hauptsächlich daS Werk Salazars, deS bauerngeborenen, schlichten und einfachen Führers seines Volkes, der sein Leben für Portugal m der Stille seiner Arbeits räume in Lissabon, unterbrochen nur von kurzen Erholungsstunden in der beschaulichen Einsamkeit seines vom Vater ererbten Landgutes in Santa Combo Dao verbringt. „Wir halten den Glauben für absurd, es fei nötig, zu korrumpieren, um regieren zu können!\" Dies« Worte des alle demagogischen Künste verschmähen den Diktators von Portugal, die er vor zwölf Jahren an den Ansang seiner Arbeit stellte, ver sucht Salazar auch aus außenpolitischem Ge» biet möglichst zur Geltung zu bringen. Wie seine innerpolitische Arbeit gekennzeichnet ist durch eine ebenso einfache wie gradlinige Planung, so ist es auch das außenpolitische Ziel Salazars, für Por tugal eine strenge und gradlinige Neutralitäts- Politik durchzuführen. Bei Ausbruch des Krieges war Salazar fest entschlossen, eine Entwicklung, wie die des Weltkrieges, da England es verstand, Portugal vor seinen KrirgAvagen zu spannen, zu vermeiden. Der portugiesische Regierungschef hat von Ansang an keinen Zweifel daran gelassen, daß er f ü r P o r t u g a l nur die Gesetze der aller- striktesten Neutralität anerkennen könne. Salazar ist davon überzeugt, daß er da mit seinem Vaterland den besten Dienst erweist. Die portugiesische Zensur läßt zwar england- freundliche Artikel erscheinen, anderseits aber hat der Liffaboner Rotstift Ausfälle gegen Deutsch- land, wie sie sich die Presse anderer „neutraler\" Länder geleistet hat, rigoros gestrichen. Portugal- Allianz mit England hat Salazar unberührt in der alten Schublade liegen lassen, in der sie seit Jahrzehnten schlummert. Sie war bislang di« einzige Rückendeckung, über die da- Kolonialreich Portugal verfügte, solange t*r spanische Nachbar auf der Iberischen Halbinsel von der gleichen Korruption, dem gleichen Parteizank und den gleichen Intrigen geschwächt wurde, wi« bog Por- lugal bor 1926. Daß aber Salazar erkannt hat, daß mit der langsamen Wiüiererstarkung Spa niens neue und natürlichere Anlehnungsmöglich, leiten auftauchen, beweist nicht nur das Freund- lchasts- und Nichtangriffsabkommen mit Spanien vom März 1939, sondern auch das in seiner Be deutung viel wichtigere Zusatzabkommen zu diesem Neuer „erfolgreicher Rückzug\" Londons Das englische Dakar-Unternehmen gescheitert DNB. Newy 0 rk 26. Sept. Nach einer amt lichen Londoner Meldung sah sich die englische Re gierung gezwungen, die Angriffe aus Dakar einzu stellen und ihre Truppen zurückzuziehen. Sie seh? ein, daß sich der Fall Dakars nicht ohne große Kampfhandlung erreichen lasse. Lkhlklngsprobe nicht bestanden tg. Stockholm 26. Sept. (Sonderdienst des SMS.) Die abenteuerliche Entwicklung, die der britische Anschlag auf Dakar infolge schwerer Regiefehler genommen hat, hat die ganze morsche Kulistenwek! enthüllt, in die sich die Reste britischer Welt- umspannungspolitik mit ihren unzulänglichen Mit teln zurückgezogen haben. Das widerliche Agenten- fpid mit de Gaulle sollte in Dakar seine erste Probe bestehen. Die Sache war seit langem vor bereitet. De Gaulle, dem namhafte Militärkritiker in England noch mit großem Mißtrauen als Aben teurer gegenüberstehen, sollte mit Einern Hand streich aus Westafrika die Lehrlingsprobe ablegen. Er erhielt gnädigst die Erlaubnis, diese afrika nische Basis mit dem Hinterland unter britische Kontrolle zu bringen. Der Auftrag, den ihm Churchill gegeben hatte, lautete, soweit als mög lich eine peinliche Wiederholung des blutigen Schandmals von Dran zu vermeiden. Man gibt heute, wie „United Preß\" feststellt, in London offen zu, daß de Gaulle offenbar die An zahl seiner Anhänger über- und den Widerstands- willen der französischen Besatzung unterschätzt habe. Man gibt weiter zu, daß die Absicht der Ausfahrt de Gaulles zu seiner ersten „Heldentat\" vorzeitig durchgesickert sein mußte und damit der Vichy-Regierung Gelegenheit gegeben wurde, ent sprechende Vorsichtsmaßnahmen in Dakar zu tref fen, so vor allem die Verhaftung aller unzuver lässigen Elemente, deren sich de Gaulle als Ver bündete im Rücken Dakars bedienen könnte. De Gaulle selbst hatte nach Möglichkeit versucht, den feigen Verrat zunächst unblutig durchzuführen. Deshalb hat auch d« Gaulle zweimal durch Parla- mentäre zu verhandeln versucht, als er aus der Höhe von Dakar angelangt war. Nun sei es zu spät. Vichy richtet Standgerichte ein Gegen die Verräter um de Gaulle — Eine späte Erkenntnis bg. Genf 26. Sept. (Sonderdienst des SMS.) Zu der beispiellosen Erbitterung der französischen Oessentlichkeit über das englische Attentat gegen Dakar und die französische Flotte kommt jetzt eine Erkenntnis hinzu: die Erkenntnis, daß Frank reich heute die Früchte seiner England politik erntet, die seit Jahren, vor allem aber von den beiden letzten Regierungen Daladier und Reynaud betrieben wurde. In Frankreich selbst ist ein Standgericht errichtet worden, um alle in Frankreich befindlichen Komplicen de Ganlles so fort aburteilen zu können. „Weil die französische Regierung genau weiß, daß de Gaulle in Frank reich Komplicen hat, deren Geschäftigkeit sich gerade in der letzte« Zeit besonders vermehrt hat und die auch fortgesetzt werden soll, hat sie das Stand- gericht eingerichtet, das den Schutz der öffentlichen Sicherheit gewährleisten und gegen alle Verräter di« entsprechenden Strafen fällen wird.\" Dieser höchst bemerkenswerte Regierungshinweis aus die in Frankreich befindlichen Komplicen de Gaulles bezieht sich zweifellos auf diejenigen v e r d ä ch - tigen Politiker, über deren Tätigkeit in den letzten Tagen mehrfach berichtet wurde. Man befürchtet in Frankreich, daß England auch gegen andere Teile des französischen Kolonialreiches den Angriff eröffnet, schon aus Nervosität über feine bisherigen afrikanischen Mißerfolge und aus dem Bedürfnis heraus, wenigstens irgendwo, vor allem gegen unterlegene gegnerische Kräfte den An- schein der militärischen Initiative zu erwecken. Nach den bisherigen Mißerfolgen vor Dakar ist man aber in London, was Pubkikation über dieses Unternehmen betrifft, schon etwas kleinlauter ge worden. Das sogenannte Hauptquartier de Gaul les darf in feinen Berichten lediglich bekannt- machen, daß die Operationen vor Dakar fortge führt werden. Afrika natürliche Ergänzung Europas Schlußbilanz italienischer Blätter über die römischen Gespräche eh. Rom 26. Sept. (Sonderdienst des SMS.) Di« kindischen Versuche der Engländer, die weittragende Bedeutung der römischen Be sprechungen dadurch verkleinern zu wollen, daß sieindenTextderbeidenTelegramme Ribbentrops und Cianos Sätze hin- e i u f ä l s ch e n, die im Original fehlen, sind für das geistige Niveau, das die Engländer ihren Nundfunkhörern zutrauen, bezeichnend. Die Chur- chillclique beginnt freilich langsam zu begreifen, daß der Krieg für England um so zerstörender sein wird, je länger der nutzlose Widerstand fortgesetzt wird. Deutschland und Italien, so betont „Gior- nale d\\'Jtalia\", haben diesen Widerstand nicht unterschätzt und haben von Anfang an gewußt, daß man ein Weltreich, das über ein Viertel der Erdoberfläche gebietet, nicht in zwanzig Tage« de- zwingen kann. Sie wissen, daßderKriegnoch nicht am Ende angelangt ist. Sic wissen aber auch, daß England eines Tages ge zwungen sein wird, sich den Plänen der Achsenmächte zu fügen, die Englands durch den bisherigen Kriegsverlauf schon erfolgte Ausschließung aus Europa festlegen und auch für Afrika daraus die notwendigen Konsequenzen ziehen werden. Die römischen Besprechungen haben, so wird in der gesamten italienischen Presse im Anschluß an die Telegramme der beiden Außenminister noch einmal nachdrücklich betont, die absolute und voll- ständige Uebereinstimmung Deutschlands und Jta- liens in „allen Kriegs- und Friedensplänen\"^ er- a u f sagt, geben. Diese Pläne beziehen sich Europa und Afrika, das, wie Gap^a ,„ a ., „nurdienatürli cheunduntrennbare Ergänzung Europas ist\". Die beiden Ach- senmächte seien bereit, England überall dort zu treffen und zu schlagen, wo eS Widerstand zu lei- sten versuche, möge dies nun in Egypten oder in welchem Gebiete immer fein. Der Ossiziosus des Palazzo Chigi weist gerade in diesem Zusammen hang aus das befreundete Spanien hin, das ebenfalls mit den in Auflösung begriffenen Demo- fratien abzurechnen hat, und das über „beherr schende Positionen einer gleichsam territorialen Verbindung Europas mit Afrika\" verfüge. Auch „Lavoro Fascista\" nennt Spanien neben Italien und Deutschland. _ Die Gefahr, daß kleine Staaten künftig wieder diese Ordnung stören könnten, werde ausgeschaltet sein: „Nachdem die Lebensräume Deutschlands und Italiens im Osten, in der Mitte, in Südosteuropa und in ganz Afrika fest- gelegt sind, wird die Konstruktion Hitlers und Mussolinis die Jahrhunderte herausfordern können wie einst das römische Imperium.\" Der englische Versuch, die Wiederholung des Verbrechens in Oran in Dakar damit zu bemän teln, daß die Anwesenheit von Streitkräften der Achsenmächte bchauptet wird, erfährt in Rom stärkste Zurückweisung. Die Vorgänge selbst wer den als neuer Beweis der verbrecherischen und räuberischen Grundhaltung der britischen Politik betrachtet. Für den Landesverräter de Gaulle über hat man auch in Italien nur Verachtung. Vertrag vom Juli dieses Jahres. Schrittweise, eine Aufgabe nach der anderen anpackend und lösend, hat Portugal sein« Erneuerungsarbeit, die Bewunderung verdient, durchgeführt. Am Anfang und am End« dieser Arbeit aber steht unver ändert schlicht und bescheiden Dr. Antonio de Oliveira Salazar, Portugals schweigender Dik tator. Norwegens Königshaus kehrt nicht zurück Kommissarische Staatsräte ernannt DSTB. Oslo 26. Sept. Reichskommissar Gaulei ter Xer hoben hielt am norwegischen Rundfunk eine grundlegende Rede. Er erklärte darin unter anderem: 1. Das Königshaus hat — erst recht, da es selbst von der Zweidrittelmehrheit des Sterlings schon abgeschrieben worden ist — keinerlei poli- tische Bedeutung mehr und wird nicht wieder nach Norwegen zurückkehren. 2. Das gleiche gilt für die ebenfalls emigrierte Regierung Nygaardsvold. 3. Demzufolge ist eine Betätigung im Sinne oder zugunsten des Königshauses oder der ge flohenen Regierung selbstverständlich untersagt. 4. Di« Tätigkeit dez Verwaltungsratcs ist bc- endet. „ B ‘ * i eS mir gemäß des Führer^Erkaffes \"E 24. April zustehenden Rechtes habe ich kom- missarische Staatsräte ernannt, die mit dem Heu- SÄW*\\' ** *<» ito -WIWe 6. Die alten politischen Parteien sind am heu tigen Tage ausgelöst worden. - 7 ‘ J5“* Zusammenschlüsse zum Zwecke einer n^cht^gedulde?^^\" poetischen Betätigung werden Papier aus Reisstroh in Spanien h der chronischen spanischen Papiernot abzu- ÄÄ der letzten Zeit Versuch« unternom- nommen worden, aus Reisstroh Papier ber.m, steifen bte befriedigend verlaufen sind. Die erste ®eri« n fafcrthötfon von Reisstrohpapier ist daher b‘£ser Tage m Valencia ausgenommen worden. Vereinfachung be r Staatsverwaltung in bet Slowakei -An der Slowakei hat die Kommission für die Vereinfachung der Staatsverwaltung ihre Arbeit ausgenommen. Da, neue System zielt auf erhöht\" »eröntroortung der Beamten bei Verminderuna h!?nr^u Xir< ^ e *: ber öe \" Staat finanziell zu stark -c.ciitciß. -Lafcurd) iDirö öIctchAcitio pino w t beslerung d-r Beamtengehüster angestrebt ^ f= LASHh \"... X* d MANDALEV SSF ! I 11: / -Ij HANOI > \\\\UTA0AD!T\\\\ VANQUN-. t‘-\" iH vsuaa . ■ 1 ^^pnqm-penh U • SAISON. S\\\\MAl (Kartendienst Erich Zander, Ml Ziim japamsch-sranzöslschen Abkommen Nach Meldungen aus Japan ist zwischen der japn- nischen und der französischen Regierung ein Ab. kommen über Erleichterungen militärischer Art in Französisch-Jndochina für das japanische Heer mti> die japanische Marine zur Durchführung des Feld- zuges in China abgeschlossen worden. Aus Grund dieses Abkommens überschritten die japanischen Truppen die Nordostgrenze von Jndochina südlich von Lungchow bei dem Grenzort Dondang. Verileltling fitr Dakar Gibraltar immer wieder bombardiert bg. Gens 16. Sept. (Sonderdienst des SMSj Wi« die letzten nach Vichy gelangten Funksprüchi besagen, ist der britische Angriff gegen Dakar aü< geschlagen worden. Also eine neue britische Nie derlage in Afrika, die diesmal noch um so schmerz licher für England sein wird, loeil jedermann weiß, daß der Angriff wieder mit überlegenen Kräften durchgeführt wurde. Ter Grund zuin Rückzug, der von englischer Seite angegeben wird, ist wieder ein Musterbeispiel grotesker Heuchel oi. Es wird nämlich bchauptet, ber britische Admiral habe im Einvernehmen mit de Gaulle den Kamps abgebrochen, weil „es unter de» gegebenen Umständen bester fei, sranzösW Leben zu schonen\". Dieser großherzige Entschluß wurde aber erst nach einer Anzahl vergeblicher Landungsmanöver gefaßt und nach einem mehrstün digen Bombardement, das am zweiten Tage vor genommen wurde und das bereits eine große An zahl von Opfern unter der französischen Zivil bevölkerung und unter dem Militär und der Ma rine gefordert hatte. Die französische Admiralität veröffentlicht soll gendes Kommunique: „Die britischen See- und Luststreitkräste hatten am 24. September einen heftigen Angriff gegen den Hafen von Dakar, gegen die Küstenbatterien und gegen das Linien- schiff „Richelieu\" vorgetragen/ Drei englische Flugzeuge wurden abgeschossen. Unsere Bomben flugzeuge haben das britische Geschwader angegrif fen- Ein . britischer Kreuzer wurde getrosten. Unsere Kreuzer haben mehrere Treffer erzielt, u. a. auf bte britischen Einheiten „Barham\" und „Resolution\" und aus einen Kreuzer vom Typ „Kent\". Am 25. September wurde von britischer Seite der Kampf fortgesetzt. Einer der beiden torpedierten britischen Kreuzer verließ den Kamps platz mit starker Schlagseite.\" Dieses französisch! Kommunique, das noch vor dem britischen Ruit zug ausgegeben wurde, zeigt schon, wie stark die Schläge der französischen Vertei diger gegen bi« britischen Angrei\\' s e T waren. Indessen werden von französischer Seite die Bergeltungsflüge gegen Gibraltar fortgesetzt. Immer neue Geschwader, von Fr««\\' zösisch-Marokko kommend, haben hundert Tonne« Bomben auf die englische Festung abgeworfen. ^tzte französische Kommunique besagt, daß das R- senal, die Mole und vor Anker liegende Einheit\" der britischen Flotte besonders heftig bombardiert wurden. Der Kreuzer „Renown, der einen 8»“’ treffet erhielt, mußte den Hasen derlasten. Joasn\\' ztell wird folgendes in Vichy weiter bekanntgegeben, daß diesmal der Schaden, den di« französischen Ber- geltungsflüge über Gibraltar angerichtet hätte«, erheblich gewesen sei. Auf dem Dnjestr, der bis zur Eingliederung Vestarabiens in öie Sowjetrepublik die Eren-e Zwischen der Sowjetunion und Rumänien gebild«\\' bat, ist nach zwanzigjähriger Unterbrechung c ; - Schiffahrt wieder ausgenommen worden. yiiiiinuiiiiiiiiiiiiiiiii!iiiiiimimimiiimiiinimni!iiiiiiiiiiiiinnninnn| | Eine Feldpostsendung mit dem Schwäbischen Merkur ist eine Freude für unsere Soldaten. Bestellungen nimmt jederzeit entgegen Verlag beS Schwab. Merkur ', 'paper_title': 'Schwäbischer Merkur : mit Schwäbischer Kronik und Handelszeitung : Süddeutsche Zeitung'}\n",
      "\n",
      "--- Entry 2 repr ---\n",
      "{'page_id': 'GTY6WLKCOIUQUTROD5AIF7YCHNQ25ITJ-FILE_0006_DDB_FULLTEXT', 'pagenumber': 6, 'publication_date': Timestamp('1940-09-09 12:00:00'), 'place_of_distribution': ['Stuttgart'], 'language': ['ger'], 'plainpagefulltext': '8 Handelszeitung des Schwäbischen Merkur, Stuttgart - Montag, den 9. September 1940, Nr. 211 Stuttgarter Pfaiidleilianstalt Rückgang der DarlehenSgesuche * Nach dem Bericht der Städt. Pfandleihanstalt Stuttgart AG, für das Jahr 1939 wurden 74 415 (i. V. 90 246) Darlehen im Betrag von 1.18 (1.45) MUL ge geben, zurückbezahlt wurden 77 883 (91 139) mit 1.24 (1.48) Mill. RM. Am Ende des Jahres lagerten noch 17 758 (21226) Pfänder mit 0.29 (0.36) Mill. RM. Der Rückgang gegenüber dem Vorjahr beträgt 64 733 RM. Nach dem Bericht wurden, um die zum Heeres dienst einberufenen Kunden vor Vermögensverlusten zu schützen, die monatlichen Versteigerungen mit Kriegs ausbruch sofort eingestellt. Das sei von der Kund schaft, die inzwischen einen erheblichen Teil der ver fallenen Pfänder eingelöst habe, d.mkbar anerkannt wor den. Die Versteigerungen sollen in Bälde wieder auf genommen werden. Einberufenen-Pfänder sollen aber auch weiterhin zurückgestellt werden. Die Zweigstelle Königstraße 10 wurde stillgelegt. Die Zahl der versteigerten Pfänder ist aus den oben angeführten Gründen auf 2916 mit 20 945 RM. (i, V. 4288 bzw. 53 821 RM.) zurückgegangen. Gesamt- pfänderumsatz 152 298 Stück (181385) mit 2.42 .2.93) Mill. RM. Täglich wurden durchschnittlich 507 (604) Pfänder abgefertigt. Die höchsten Zahlen erreich ten die Darlehen von 6 bis 10 und von 3 bis 5 RM. Eine große Arbeitsbelastung brachte die Verordnung, die die öffentlichen Pfandleihanstalten als Ankaufsstellen für die von den Juden zum Kauf anzubietenden Gegen stände aus Gold. Platin, Silber, Edelsteinen bestimmte. Diese Treuhandtätigkeit brachte dem Unternehmen auch höhere Einnahmen, insgesamt 45 620 (14 196) RM. Zur Abwicklung der Geschäfte der Ankaufsstelle für die jüdischen Wertgegenstände war ein kurzfristiger Kredit nötig, wodurch die Zinsen sich auf 24 858 (17 522) RM. erhöhten. Das Grundkapital wird wieder mit 4 v. H. aus einem Gewinn von 9852 (4645) RM. verzinst, der Sicherheitsrücklage wird ein Betrag von 5652 (645) RM. überwiesen. In der Biltnz erscheinen die im Aufträge des Reichs angekauften Wertgegenstände mit 233 299 Reiechsmark. Riimlerlasse des KdF. Kein Rechtsanspruch Durch Urteil vom 23. Dezember 1936 — veröffentlicht im „Reiehssteuerblatt“ (R.St.Bl.) 1937 8, 677 — hat der Reichsfinanzhof entschieden, daß der Steuerpflichtige auf eine nach § 13 Ziff. 1 AG. gewährte Befreiung einen Rechtsanspruch hat, den er im ordentlichen RechVsmittelverfahren verfolgen kann. Diese Entschei dung erging durch den Sechsten Senat für das Gebiet der Lohnsteuer. Gegen diese Entscheidung nahm nun der Vierte Senat in einem Urteil vom 4. Juli 1940 (-R.St.Bl. S. 678) Stellung. Es handelt eich hier um die Abgrenzung zwischen Verwaltung und Rechtsprechung auf dem Gebiet des Steuerrechts. Der Reichsfinanzhof führt hiezu aus: „Es ist zuzugeben, daß der Reicheminister der Finanzen sich der Rund erlasse bedient, um die ihm nach § 17 Satz 1 AG. zustehende oberste Leitung auszuüben. Deshalb sind Runderlasse in erster Linie für die Reichsfinanzverwal tungsbehörden bestimmt. Da der Reichsminister der Fi nanzen erklärt hat, daß er allgemeine Steuererlasse aus Billigkeitsgründen für bestimmte Arten von Fällen nach § 13 AG. nur in Form von Rechtsverordnungen und nicht durch Runderlaß verfüge, so kann nicht mehr angenommen werden, daß in einem Runderlaß ein Steuererlaß aus Billigkeitsgründen nach § 13 AG. ge währt worden ist, auf den ein Steuerpflichtiger Anspruch hat. Einen solchen Rechtsanspruch hat. ein Steuerpflich tiger nur dann, wenn der Steuererlaß durch Rechte verordnung ausgesprochen worden ist oder wenn eine zuständige Finanzbehörde im einzelnen Fall einen Steuererlaß bewilligt hat. Durch einen Runderlaß des Reichsministers der Finanzen wird aber einem Steuerpflichtigen kein Steuererlaß bewilligt, weil der Runderlaß nur für die Finanzverwaltungsbe hörden bestimmt ist. Die Runderlasse des Reichsmini- eters der Finanzen über die Steuerbefreiung der W e i h- na chtsgeschenke enthalten deshalb nur eine Anweisung an die Finanzämter, unter den dort näher bezeichneten Voraussetzungen keine Steuer. anzufordern oder die Haftung für den unterlassenen Lohnsteuerabzug dem Arbeitgeber gegenüber nicht geltend zu machen. Zweifel über die Auslegung eines solchen Runderlasses können nicht von den Steuergerichten entschie den, sondern müssen von den Finanzverwal tung s behörden, in letzter Linie von dem Reichs minister der Finanzen, geklärt werden.\" Mit dieser Entscheidung hat sich der Reichsfinanzhof dem Rechtsstandpunkt des Reichsministers der Finanzen angeschlossen. Die Rechtsauffassung des Reichsmini sters der Finanzen ist ausführlich in einem Schreiben desselben an den Reichsfinanzhof dargelegt und im R.St.Bl. 1940 8. 756 veröffentlicht. Es ist dort ausge führt: „Die Frage, ob über die Anwendbarkeit und über die Auslegung von Runderia sssn ausschließlich die Ver waltungsbehörden zu entscheiden haben, kann m. E. für alle Runderlasse nur einheitlich beantwortet wer den. Es kann m, E. nicht zwischen veröffentlichten oder nicht veröffentlichten Runderlassen unterschieden wer den.“ Nun ist diese Frage endgültig entschieden, und zwar zugunsten der Verwaltungsbehörden. Assessor Kochendörfer § [Dividenden erschlage.) Vöslauer Kammgamfabrik wieder 6 v. H. Jugoslawische Aulhaupläue Besonderer Schutz für die Landwirtschaft Ha. Belgrad 2. Sept. Jugoslawien befindet sieh auf dem Wege zu einer staatlich gesteuerten Wirtschaft, die durch eine Reihe von Regierungs verordnungen eingeleitet wird. Durch diese Maßnahmen soll die allgemeine Erzeugung nicht nur nicht gestört, sondern nach Möglichkeit noch vergrößert werden, je doch soll der Geyinn eingeschränkt, der Zwischenhan del möglichst beseitigt und die Waren sollen dem Ver braucher leichter zugänglich gemacht werden. Vor allem aber soll der Landwirtschaft, mit der sich etwa 80 v. H. der Bevölkerung befassen, der größt mögliche Schutz gewährt und die sozialen Unterschiede und ungerechtfertigte Zustände sollen besser ausgegli chen werden. Trotz dem Uebergang zu einer gesteuer ten Planwirtschaft wird der Staat der privaten Unter nehmungslust Möglichkeiten zur Entfaltung geben. In erster Linie wird eine Verordnung über die Organi sation der Erzeugung und des Handelsver kehrs erscheinen. Ferner soll die Teuerung durch wirksame Regierungs nußnahmen bekämpft werden; die entsprechende Verordnung ist bereits vom Ministerrat unterzeichnet, worden. Was die viel erörterte Frage der Reorganisation der Nationalbank anbelangt, so wird voraussichtlich die Anzahl der Mit glieder des Verwaltungsrates, die von der Regierung delegiert werden, vergrößert werden, so daß die Majori tät der Regierung in der Verwaltung dieses Instituts in jeder Hinsicht gesichert wird. Zur Ausführung von gro ßen öffentlichen Arbeiten — für Eisenbahn- bauten und zur Beschaffung von Eisenbahnmaterial wer den 1.5 Milld. Dinar benötigt — und andere Zwecke ist die Ausgabe einer inneren Anleihe von 6 Milld. Dinar vorgesehen, an der sich alle Kreise der Bevölke rung, insbesondere jedoch die Wirtschaft, im Verhält nis zu ihrem Vermögen durch Zeichnung der Obligatio nen beteiligen sollen. Im Zuge der gesteuerten Wirt schaft ist auch die Ausdehnung der Kontrolle der Einfuhr auf Waren aus Nichtclearingländern vorge sehen, so daß in Zukunft jede Einfuhr der Kontrolle unterstehen wird. Das Verhältnis zwischen Kapital und Arbeit soll ebenfalls geregelt werden, so daß in Zukunft die Gegensätze zwischen diesen beiden Faktoren ausge schaltet werden. Streiks und Aussperrungen werden verboten; alle sich etwa ergebenden Un stimmigkeiten sollen durch Vermittlung eines Arbeits gerichtes geordnet werden. Moskau wird Seestadt Der große russische Binnenschiffahrtsplan 0 Das interessanteste Vorhaben des großen Aufbau- werkes der Sowjetunion ist der bereits in Ausführung begriffene Plan, ein riesiges Netz von Was serverbindungen zu schaffen, das alle Gebiete des russischen Reiches miteinander in Verbindung brin gen wird. Moskau wird dadurch der zentrale Hafen von fünf Seengebieten werden. Man schachtet bereits von hier aus Kanäle aus, die auch für klei nere Seeschiffe befahrbar sein werden und nach dem Kaspischen Meer, dem Schwarzen Meer, dem Asow sehen Meer, dem Weißen Meer und dem Finnischen Meerbusen führen. Man arbeitet mit Hochdruck an der Fertigstellung dieser neuen Wasserstraßenverbindungen. Der Stalin kanal, der von Leningrad durch den Ladoga- und den Onegasee nach Murmansk geht, ist schon fertigge stellt. Ein anderer Kanal, der fünf Meter tief und 55 Meter breit wird, wird Moskau mit der Wolga verbinden und hat nur eine Länge von 127 Kilo metern. Auf diesem Wege erreichen die Schiffe das Kaspische Meer. Eine andere Kanalverbindunsr besteht bereits zwischen dem Stalinkanal und Moskau und da mit zwischen dem Finnischen Meerbusen, dem Weißen und dem Kaspischen Meer. Durch riesige Dämme wird das Wasser der benachbarten großen Ströme gestaut, um einen Moskausee zu schaffen, der der Hafen der Hauptstadt werden soll. Des weiteren wird ein Wasserweg zwischen dem Don. der in das Asowsche Meer fließt, und der Wolga gegraben. Hieran arbeiten bereits 20 000 Arbeiter und 100 Ingenieure. Dieser Kanal schafft die Verbindung zwischen den nörd lichen Seen, dem Asowscben und dem Kaspischen Meer. Eine andere Wasserlinie schafft eine direkte Verbin dung zwischen Moskau und dem Schwarzen Meer. Sie geht von der Oka au», einem Nebenfluß der Wolga, und führt in die Deena, die ihrerseits ein Nebenfluß des Dnjcpr ist. Wenn alle diese Pläne Wirklichkeit geworden sein werden, wird das Petroleum von Baku am Kaspi schen Meer ohne Umladung nach allen Gegenden Ruß lands verschifft Werden können. Die Kohlen aus dem Donezbeeken sind dann in allen russischen Provinzen verfügbar, wodurch sich für die Industrie und die Landwirtschaft, die zu einem erheblichen Teil bereits motorisiert ist. neue Möglichkeiten eröffnen Moskau aber, das bis jetzt in einer unermeßlich großen Steppe lag. wird einer der bedeutendsten Binnenhafenplätze der Welt werden. Wirtschafts-Umschau 8 |Eine neue Kartoffelkonserve.) Bekanntlich ist es eine stete Sorge der Landwirtschaft, die Verluste, die beim Einlagern der Kartoffeln entstehen können, mög lichst zu verringern. Wie das „Algemeen Handelsblad“ mitteilt, ist es in Holland gelungen, aus Kartof feln eine Dauerware herzustellen, die Jahre lang eingelagert werden kann, einen Kartoffel grieß, dem alle in der Kartoffel enthaltenen Nähr werte einschließlich eines Teils des Vitamins C erhalten bleiben. Der Kartoffelgrieß ist von angenehmem Ge schmack und kann Weizenmehl zum Teil ersetzen. Es handelt sich also um eine neue Kartoffe Ikon serve, die keineswegs mit Kartoffelmehl verwechselt werden darf. § [Schwedisch-sowjetisches Wirtschaftsabkommen ab geschlossen.) Als Ergebnis mehrmonatiger Verband« hingen wurde am 7. Sept. in Moskau ein Wirtschafts und Zahlungsabkommen sowie ein Kreditabkommen zwi schen der Sowjetunion und Schweden unterzeich net. Im ersten Jahre seiner Gültigkeit sieht das Wirt- schafts- und Zahlungsabkommen einen Warenaus tausch in der Gesamtsumme von 150 Mill. Schweden kronen vor, sodaß auf jede einzelne Seite 75 MM. Schwedenkronen fallen. § [Großhandelspreise in Großbritannien um 40 v. H. gestiegen.] Wie die „Irish Times\" am 3. Sept. berich tet, waren nach amtlichen Angaben die Großhandels preise in Großbritannien im Juli etwa 40 v. H. höher als im vorhergehenden Monat. § [Englische Guthaben in Frankreich blockiert.) Nach einer Meldung des „Exportateur francais\" hat als Ant wort auf die Blockierung französischer Guthaben in Großbritannien die französische Regierung sämtlichen Kreditinstituten und Börsenorganisationen die Anwei sung gegeben, Guthaben auf Kredit britischer Staatsangehöriger ebenfalls zu sperren. — Nach der gleichen Quelle wurden die französischen Kon ten in Schweden blockiert, um den schwedischen Ausführenden die Möglichkeit zu schaffen, ein Entgelt für ihre Lieferungen nach Frankreich zu erhalten. Die gleiche Zeitung führt als Länder, mit denen noch Clearing-Abkommen laufen, auf: Spanien, die Schweiz, Griechenland. Ungarn, die Türkei, Jugosla wien, Argentinien, Chile. Eri« erbsgeselischaften § [paber-Bleistift-Ge Seilschaften.) Die Entwicklung der deutschen Bleistiftindustrie hat im Jahre 1939 ein befriedigendes Umsatzergebnis gebracht. Vor allem hat die erhöhte Aufnahmefähigkeit des erweiterten grob- deutschen Marktes, wie aus den Geschäftsberichten der Gesellschaften des Faber-Bleistift-Konzerns Nürnberg hervorgeht, zu einer erheblichen Verbes serung des Inland Umsatzes beigetragen. Im Ausfuhrge schäft hat die deutsche Bleistift-Industrie ihre Be mühungen zur Aufrechterhaltung des bisherigen Aus fuhrvolumens fortgesetzt. Der A. W. Fab er Ca «tell-BleistifX-Fabrik AG. in Stein bei Nürnberg ist es gelungen, die Ausfuhrumsätze im abge laufenen Geschäftsjahr annähernd zu behaupten. Nach Abzug aller Unkosten wird bei Faber-Castell ein Rein gewinn einschl. Vortrag von 293 008 (291 661) RM aus gewiesen, aus dem laut HV.-Beschluß, wie bereits kurz gemeldet, wieder 7 v. H. Dividende verteilt und 118 008 Reichsmark auf neue Rechnung vorgetragen werden. Der Rohüberschuß ist mit 4.84 Mill. RM um etwa 410 000 RM höher. Auch sonstige Erträge sind stark ge stiegen mit 910 000 RM gegen 110 000 RM i, V. Das Lohnkonto ist mit 3.41 (2.95) Mill. RM eingesetzt. Der Verlauf des ersten Halbjahres 1940 sei zufriedenstellend, die Umsätze lägen etwas höher als i. V. Das euro päische Ausland zeige eine zunehmende Aufnahmebe reitschaft. Frühere Ergebnisse konnten teilweise weit überholt werden. — Das Geschäftsergebnis der Blei stiftfabrik vorm. Johann Faber AG. war ebenfalls zufriedenstellend, das Ausfuhrergebnis blieb nahezu auf dem Stand des Vorjahres. Die rumänische Bleistiftfabrik Siviu blieb gut beschäftigt in Verbindung mit der Castell-Apollo-S.A.R., Siviu. Die Lapis-Faber- Sao Paulo setzte die Bearbeitung des brasilianischen Marktes erfolgreich fort. Die HV. beschloß, aus einem Reingewinn einschl. Vortrag von 209 424 (195 259) RM wieder 5 v. H. auf die St.A. und wieder 6 v. H. auf die VA. zu verteilen. Auf neue Rechnung werden 147 864 (133 699) RM vorgetragen. Der Rohgewinn wird bei dieser Gesellschaft mit 2.27 (1.94) Mill. RM eingesetzt, denen Löhne und Gehälter mit 1.54 (1.47), Abschreibun gen von 0.06 (0.08) und Steuern mit 3.39 (3.36) Mill. RM gegenüberstehen. Ueber das laufende Jahr wurde eine bisher befriedigende Entwicklung der Umsätze be obachtet. § [Mechanische Weberei AG., Zittau.) Die Gesellschaft schließt für 1939/40 nach Abschreibungen von 0.15 (0.09) Mill. RM mit einem Gewinn von 0.23 (0.16) Mill, ab, um den sich der Verlustvortrag von 0.78 (1.01) Mill. RM ermäßigt. 8 [Vereinigte Fränkische Schuhfabriken AG., Nürn berg.) Die gemeldete Zuwahl von AR.-Mitgliedem aus der württ. Lederwirtschaft und Schuhindustrie erfolgte, wie vom ..Fr. K.“ ergänzend mitgeteilt wird, bereits am 27. April 1939. Börsen vom Tage Freundlich und teilweise wieder fest Berlin 9. Sept. (Big. Tel.): Die Börse war auch za Be ginn der Woche freundlich und einzelne Wert\" wieder fest. Es zeigt sieh wieder eiiuaii daß nach kurzenSchwächeperioden wie in der Vorwoche, der Anlagebedarf des PubükaiM den Ausschlag gibt. Ueberwiegend lagen die heut> a Anfangskurse 1 bis 1.5 über vorgestern Großen von etwa 3 hatten Bremer Wolle und Südd. Zucker A Elektromarkt traten AEG. etwas mehr hervor Mm rechnet nach wie vor in absehbarer Zeit mit einer\" Ne a . emission. Am Montammarkt hatten Harpener <u 6 pjj rung. Von sonstigen variablen Werten waren Dai* stärker gefragt und 1.5 fester. Variable Kurse; Harpener 154.75, Mannesmann 189 Ti Rheinstahl 158.75. Stahlverein 129%—129.75, Erdöl iw bis 157.5, Salzdetfurth 205.5. Farben 188, Conti-GuaJ 294.5, Deutsche Linoleum 178. AEG. 165 bis 164.5 gT fürel 179—179.25, Lahmeyer 148.75—148.25, Siemens ggs bis 252, Dessauer Gas 148, Felten 182.25, BMW ,» bis 179, Daimler 168, Demag 178, Deutsche W s fU 189.75. Maschinenbau-Bahnbedarf 141.75—142, Eisenhm del 189.5, Berger 195.5, Holzmann 214—214.5, Beat»» 174.5, Bremer Wolle 204.5, Dierig 212, Alsehzell 142 K, 141.5, Waldhof 162, Hotelbetriebe 112.75. Junriu M 127.75, Südd, Zucke r248. Westdeutsche Kaufhof i£ Reichsbank 118—118.25, Reichsbank 118—118.25, Reich öahnvorzuge 126%. Freiverkehr: Burbach 116. Eis.-bad. Wolle 125.5,. J[ij u. Genest 142.5, Oberbedarf 95.5, Scheldemandel 1303 Anleihen ebenfalls überwiegend fest. Die neue 4 v H Reichsschätze, Folge 4, wurden heute erstmals notiert mit 100 Geld repartiert. Altbesitz weiter fest 154%, Am Geldmarkt war Ttgesgeld unverändert 1.75-j Am Devisenmarkt kam das Pfund aus Zürich \"mit 17.60, der Franken mit 9.95. Der Dollar mit 4.89% ubÜ die Reichsmark mit 175%. * Stuttgart (Eig. Ber.): Die Tendenz war weiter fest, aber weniger infolge größerer Nachfrage, als vielmehr wegen ungenügenden oder gänzlich fehlenden Auge- botes. Einige sogenannte „schwere\" Werte waren be sonders stark erhöht. Am Aktienmarkt notierte nach Pause Knorr 10 (290) Erlangen-Bamberg 7 (187), höher Geld Daimler eben-’ falls fest mit 167 (plus 2). Feinmech. holten die Ein- büß vom Samstag wieder auf (167). Württ. Hypotheken, bank erreichten 120 (plus 2), blieben aber noch ange boten. Größeren Umsatz verzeichneten Reichsbank bi 117%. Der Rentenmarkt hatte weder Umsätze noch Kurs- Veränderungen von Belang. Weiter befestigt\\' Deutsch» Anl.-Auslos.-Scheine mit 154.5. Steuergutscheine gingen etwa zu den letzten Harem, Berliner Devisenkurse 9. Sept | Geld { Brief 9 Sept j Geld | Briet 9. Sept Geld Brid Afghanis! I 18.7918 83 Holland 132.57(132.83 Norweger. 56.76 56.88 Argentinien\\' 0 577! 0 579 ran 14 59 14.61 Portugal 9.89 9.91 Belgien 39 96 140 -04 Island 38.42 38 50 Schweder 59.46 J59.5B Brasilien 0-1301 0 132 Italien 13.09 13.11 Schweiz 56.79 56.91 Bulgarien 30 47 3 053 Japan ! 0.585! 0 587 Slowake, 8.5918.6$ Dänemark 48 21 48 31 Jugoslavä 5.604 5 616 Spanien 23-56 2J.« Estland 62 44 62 56 Lettland 48.75 (48 35 Türkei 1.978! 1*2 Finnland ! 5.06 ; 5 07 Litauen 41 94 42 02 Uruguay 0 9C4 öS GriechenlJ 2.148 2 152 luxembur o o a USA 2.498j 2-502 Ernt es cli Sitzung eil in ISA. - an. Rom 29. Aug. Nach einer telegraphischen Nach richt, die das Internationale Landwirtschaftsinstitut in Rom vom amerikanischen Landwirtschaftsminieteriam . erhielt, werden die Ergebnisse der neuen Ernte in den Ver. Staaten nach dem Stande der Kulturen im August wie folgt geschätzt: Weizen: Die Gesamterzeugumg an Winter- und Frühjahrsweizen wird auf 207 Mill. dz geschätzt, das sind 8.7 Mill. dz mehr als vor einem Monat. Die neue Ernte wird danach 0.7 v. H. größer sein als die vor jährige Ernte, die endgültig mit 205.5 MilL dz festge stellt wurde, und 6 v. H. größer als die Durch- schnittsernte von 195.2 MilL dz in dem Fünf* jahreszeitraum von 1934 bis 1938. Mais: Die Maisernte wird auf 571.1 Mill. dz ge schätzt gegen 613 Mill. dz vor einem Monat. Die neue Schätzung liegt 14.2 v. H. unter dem endgültig® Ergebnis der vorjährigen Maisernte, übertrifft jedoch die Durchschnittsernte des Fünfjahresabschnitts 1934/38 um um 7.2 v. H. Hafer, Gerste, Roggen: Die Schätzung der Hafer-, Gersten- uyd Roggenemte lautet auf 1®-» Mill. dz, das sind 19.7 v. H. mehr als das endgültig* Ergebnis der 1939er Ernte und 18 v. H. mehr all das Durchschnittsergebnis in den Jahrs 1934/38. Die Gerstenernte allein wird auf 63.1 Mill. a geschätzt, das sind 4.9 v. H. mehr als im Vorjahre und 41.6 v. H. mehr als im letzten Fünfjahresabschnitt. Die Roggenernte wird auf 9.5 Mill. dz geschätzt, das sind 4.6 v. H. weniger als im vergangenen _ Jahre und 9.3 v. H. weniger als nach dem letzten Fünfjahrea durchschnitt. Andere Kulturen: Die Flachsernte wird a™ 7.4 Mill. und die Reiserate auf 11.2 Mill. dz geschätzt; beide liegen leicht über dem endgültigen Ergebnis de* Vorjahres. Die Kartoffelernte wird auf 10W Mill. dz geschätzt. Die Schätzungen der Tabak- und der Hopfenernte bleiben hinter den Schätzung® vor einem Monat etwas zurück und liegen au» unter dem letzten Fünfjahresdurchschnitt. Stuttgarter Börse vom 9. September 1940 fndüstrle Bamberg« Miliarei Bivmw. Unter ha u«en Brauerei Wolle BürgerlichetBrauhaui Ravensburg Deimler-Benz i.G. Dt Linoleumwerte AG. Erlangen Baumwolle Ulingen Maschinen!. Farbenindvitrie IG. Feinmeck Teltlingei Gesellschaft l dafür. Unternehmungen Heidelberg Zementw. Heiser Maschinen!. Hmmetwk.AG.Tübing Hohler, Trociingen Holzwerkieuglabnk Laupheim IG Junghanl Gebr. Kammgarnspinnerei Bietigheim 7. 9. 155 G 158 ° 170 G 170 G 112 G 112 U 115 ß 115 0 165 G 167 0 180 b 180 b 187 0 141 etbG 142 0 187V« G 188V« 165 etbB 167 etb — 178 G 180 G 179 G 200 G 200 0 256 G 266 ß 145 ß 145 0 104 0 105 0 lzrv» G 127 0 161 G 161 0 114 etbB 114 B Knorr, C. H. Heilbronn Kolb iSchüle.Kirchh Kraftwerk Allwürtlbg. Vlsschinlb. Weingart Mittelichwibische Ueberlandzentrale \\\\iackern. Ui. Stamm NSU-Werke AU. Jitertag-Werke AG ialzwerk Heilbronn 143 96V* Spinnerei Pleraee StultgartBäckermühlc StuttgwLGipigoichSit Stuttgarter Hotbräu Stuttg. Vereinibuchdr. Südd. Baumwolle- Indualrie Kuchen Südd. Zucker Mannt, U Inter Brauerei Verein d Oeltabriker, 13S Verein. Cilwer Decken 128 9. 290 143 96V« 168 G169 0 128 175 147 285 136 143 180 175 141 235 114 53 148 243 121 128 176 147 G 290 136 143 180 175 141 235 114 55 148 245 121 135 129 Verein gle Filzfabriken Vera«, Trikotfabriken Woll ,. Weilderatadt Württ. Spinn -«. Web. bei EIllingen Württ.Catfttnmanulakt W. Elektr. AG Stuttgari Württ. Leinen Industrie Blaubeuren Württ-Metallwarenlabi Ziegel*.Ludwigiburg Banken Commerz- o. Pr.-Bank Deutsche Bank Deutsche Reichsbank Dresdner Bank ß Württ. Bank Württ. Hypothek-Bank Verkehr Reichib..Vorz.-Aklien Schleppsch.Heübronn Stuttg. Straßenbahnen Versicherung, Allianz o. Stuttg. Leb. Allianz o. Stuttg. Vera. Württ. Feuervere AG Q,Württ. u Bad.Ver Vera Gl t ln 7. 9. 108 B 108 etb 115 G 115 G 126 G 127 G 158 G 158 G 190 0 190 U 148 G 148 G 142 n 142 G 200 B 200 8 166 G 166 G 129 b 129V* G 137 b 137 G 117*/s b 128\\'/« G 128\\',e ß 115 G 115 G 118 G 120 bB 126*/« G 127*/« G 80 G 80 G 135 G 135 G 90 B 90 etbB 26\\' i G FsslTsniosl. Werte Staatspapiere mit Zinsberechnung 5% 0. Reichten! 27 4 1 /» do. 19SS 2.Ausg do 1959 2-Aueg 4Vi% Schatzanw. d. D R. 1955 Folge V do. 1935 verlosb 1936 veiiosb 1956 2. Folge 1956 3 Folge 1937 1. Folge 1937 2 Folge 1937 3 Folge 1938 1 Folg: 1936 2 Folge 1938 3. Folgt oo. 1938 4. Folge AI*) 1940 1. Folge do. 1940 2. Folge de 1940 3. Folge do. 1940 4. Folge 4°,oD. Reichsanl.1934 5Vt°A> Voung.Anleihe A\\'.iO Reichsbahnen!! von 1935 do von 1936 do. von 1939 do. do do do do. do. do. do. do. 101’-s G 101» 102 G 102 Prozenten vom Einlösungsbetrag 7. 103 G 101-, * G 101 Va G lOIVs 0 im»,’« 6 101-,« G 102 elbB 101-« G 101-/. G 101-. G 101-.-« G 101-/« G 101--. G 100 0 100 G 100 G 100 G 9. - G 101-,. G 101\"e G lOIVs G 101-« G lOl\\'/a G 101V» b 101-/. G 101-/. G 101-/. U 101*/* G 101» *bQ 101-/. ü 100 * 100 100 100 100 AViD.Reichsposlscb. 1985 Folge I 1939 Folge I ohne Zinsberechnung D. Anleihe Auslosung einschl. *,» Ablös Steuergutecheine vom II. 12. 37 Au. B Stadtanleihen mR Zinsberechnung 4Vs EBIinger Stadt 4Vs Heilbr. Stedten! 5 0 /o Reutl. Stndtnn! j 5 % Schrämt) Stadt f 5°/o 8tuttg.S1adtanl.j- 3°*>Tübing.Stadtanl.j 4*/i Ulmer Städten! 5Vo do. t Zweckverbände 4Vi Oberachw. El.Wk Pfandbriefe mR Zinsberechnung Württ. Land.Krad. Anst 4Vi°/o Goldobligat. AVaVo Reihe 2 4V.°A> *V«°A> 4V. 0 *, 4Vi Ve *Ve°» 154 etb 3 Reihe 4 Reihe 5 Reihe 6 Reihe 7 101 101 101 101 101-/. 101 101-/. 101*/* 101\\'/. G 101 101 101 101 101 101 101 - G 154V* 101 0 101 G 101 G 101 G lOlVi G 101 G 101-/« G 101V. G 101V« 101 101 101 101 101 101 101 Pfandbriefe mit Zinsberechnung 4*/> D. Centralboden- kredit-Pf. Em. 11 4Vi do. Em 12 Vereinsbank Nürnberg 4Vs°*> Serie 1-31 4V> Serie 32-34 *V*>mm-0bl St Württ. Hypothek.-Bank 4*/. Gold 1-4 u. 9 4V*Ser.10,12u.13 4 1 /. ’*> Serie 14 4‘/> Serie 5,7 0.8 4Vi°A> Serie 15 4>/.°*> Serie 16 4V»°/t> Serie 6 4V.RM.-P1d. S. 17 4»/. do. Serie 18 4V.Kom.-Obl, S.1 Württ. Kreditverein 4>/> Gold-Ptandbr Reihe 1 4V. Reihe 3 4V. Reihe 4,3 u. 9 4‘/> Reihe 10 u.11 4 V. Reihe 12 u. 13 *V«Reine Uu. 15 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 ß 101 ß 101 101 101 101 10) 101 101 101 101 101 101 101 1101 G 101 101 *Vt°/o Reihe 16 4 1 /* Reihe 6 u. 8 101 G 101 G 9. 101 Gl 101 G| Wh *V«°A> I 7 - I 9- Reihe 17 101 G 101 Reihe 181101 Gl 101 Industrielle Schuldverschreibungen mR Zinaberechnung : 5% Daimler-Benz 4*/i Energievereorg Schwaben AB. 40 A\\'/sJ.G. Farben 1935 5°*> Neckar-Gold 5°A> Heckararerke 7. 104V* 101*/* 104 100 103*/* 9. 105 G 101»/« G 104 G 100 G 103V« G 6 Yo RSU Ver. Fahrz 5°/o Schlueheeewk.39 4»/iVorarlb.Jllwerk3S ohne Zinsberechnung: J. 6. Farben Twilach. Mesch. Fahr. EBIingen Reckar-AG. 1921 7. „ 102 G 104 G 101 Ve 143V« G 100 ß 100 G 9. , 102 l 104 | 101\\'» ö 143*/* jj 100 ° 100 G Stuttgarter Freiverkehr Bleicherei Uhingen Brauerei CU Hetheim Lautlewer Zement 7. 9. 110 G 110 ß 106*/* G 105*/» G 120 G 120 G 205 0 205 G Saline Ludwigshalle Sctioßaartan-Bai vm> 16. 210 70 100 210 “ 70 “ lOOV» 0 Veränderliche Kursnotierungen Deutsche Anleihe. Aullosungsscheine einseht. ■/. Abi Oaimlsf Motor Dt. Linoleum EBIinger Maschinen I. G. Farbenindustrie \"einmeeh. Tutsi innen 7. 154 165V* 140V. 187V« 154V. 0 167 bG 179 0 187\\' Geilüret Heidelberg Zementwk. Hetaer Jungbans Neckarwerte Südd. Zucker Deutsche Reichibenk 7. 180 200 127\\'/ _ 0 179 0 200 127 6 ', 'paper_title': 'Schwäbischer Merkur : mit Schwäbischer Kronik und Handelszeitung : Süddeutsche Zeitung'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect the loaded data structure\n",
    "print(\"Loaded 'articles' object type:\", type(articles))\n",
    "try:\n",
    "    print(\"Length of articles:\", len(articles))\n",
    "except Exception:\n",
    "    pass\n",
    "# Show first three entries for structure\n",
    "for i in range(min(3, len(articles))):\n",
    "    print(f\"--- Entry {i} repr ---\")\n",
    "    try:\n",
    "        entry = articles.iloc[i]\n",
    "        print(entry.to_dict())  # show full row as dict\n",
    "    except Exception as e:\n",
    "        print(\"Error accessing row via iloc:\", e)\n",
    "        entry = articles[i] if isinstance(articles, list) else None\n",
    "        print(repr(entry)[:500])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If loaded as DataFrame, use it; else convert list of dicts to DataFrame\n",
    "if isinstance(articles, pd.DataFrame):\n",
    "    df = articles\n",
    "elif isinstance(articles, list) and isinstance(articles[0], dict):\n",
    "    df = pd.DataFrame(articles)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported data format: expected DataFrame or list of dicts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the text column\n",
    "TEXT_COL = 'plainpagefulltext'\n",
    "if TEXT_COL not in df.columns:\n",
    "    raise KeyError(f\"Expected column '{TEXT_COL}' not found in DataFrame\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize tools\n",
    "# Ensure spaCy German model is installed and loaded\n",
    "def load_german_model(name='de_core_news_sm'):\n",
    "    try:\n",
    "        return spacy.load(name)\n",
    "    except OSError:\n",
    "        print(f\"Model '{name}' not found. Downloading...\")\n",
    "        spacy_download(name)\n",
    "        return spacy.load(name)\n",
    "\n",
    "nlp = load_german_model('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize spaCy German model\n",
    "try:\n",
    "    nlp = spacy.load('de_core_news_sm')\n",
    "except OSError:\n",
    "    spacy_download('de_core_news_sm')\n",
    "    nlp = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take correction code for German, found on Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "corrector = pipeline(\n",
    "    task='text2text-generation',\n",
    "    model='oliverguhr/spelling-correction-german-base',\n",
    "    device=-1  # set to -1 if using CPU only\n",
    ")\n",
    "\n",
    "# Cache for corrected tokens\n",
    "correction_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text(text):\n",
    "    doc = nlp(text)\n",
    "    corrected_sentences = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        s = sent.text\n",
    "        tokens = re.findall(r\"\\b\\w+\\b\", s)\n",
    "        for tok in tokens:\n",
    "            if is_valid_word(tok) and tok not in correction_cache:\n",
    "                # valid and not previously corrected\n",
    "                continue\n",
    "            if tok in correction_cache:\n",
    "                replacement = correction_cache[tok]\n",
    "            else:\n",
    "                prompt = (\n",
    "                    f\"Korrigiere das falsch erkannte Wort '{tok}' im deutschen Satz: \\\"{s}\\\".\"\n",
    "                    \"Gib nur das Ersatzwort zurück.\"\n",
    "                )\n",
    "                out = corrector(prompt, max_length=16, num_return_sequences=1)\n",
    "                replacement = out[0].get('generated_text', '').strip() or tok\n",
    "                correction_cache[tok] = replacement\n",
    "\n",
    "            s = re.sub(rf\"\\b{re.escape(tok)}\\b\", replacement, s)\n",
    "        corrected_sentences.append(s)\n",
    "\n",
    "    return ' '.join(corrected_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "# 4. Test on first 3 entries\n",
    "small = df.head(3).copy()\n",
    "small['corrected_text'] = small[TEXT_COL].fillna('').apply(correct_text)\n",
    "df['corrected_text'] = corrected_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m df_small = df.head(\u001b[32m10\u001b[39m).copy()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Apply corrections row-wise on df_small only\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_small[\u001b[33m'\u001b[39m\u001b[33mcorrected_text\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf_small\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTEXT_COL\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrect_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Attach corrected column back or use df_small directly for saving\u001b[39;00m\n\u001b[32m      7\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mcorrected_text\u001b[39m\u001b[33m'\u001b[39m] = corrected_texts\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/pandas/core/series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/pandas/core/base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mcorrect_text\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     15\u001b[39m     prompt = (\n\u001b[32m     16\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKorrigiere das falsch erkannte Wort \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtok\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m im deutschen Satz: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGib nur das Ersatzwort zurück.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     out = \u001b[43mcorrector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     replacement = out[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m).strip() \u001b[38;5;129;01mor\u001b[39;00m tok\n\u001b[32m     21\u001b[39m     correction_cache[tok] = replacement\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/pipelines/text2text_generation.py:186\u001b[39m, in \u001b[36mText2TextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    158\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[32m    160\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    183\u001b[39m \u001b[33;03m          ids of the generated text.\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    188\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m    189\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[32m0\u001b[39m])\n\u001b[32m    190\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[32m    191\u001b[39m     ):\n\u001b[32m    192\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/pipelines/base.py:1431\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1424\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1425\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1428\u001b[39m         )\n\u001b[32m   1429\u001b[39m     )\n\u001b[32m   1430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/pipelines/base.py:1438\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1436\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1437\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1438\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1439\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/pipelines/base.py:1338\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1336\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1337\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/pipelines/text2text_generation.py:215\u001b[39m, in \u001b[36mText2TextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    213\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m output_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m out_b = output_ids.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/generation/utils.py:2412\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2408\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`attention_mask` passed to `generate` must be 2D.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[32m   2411\u001b[39m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2412\u001b[39m     model_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[32m   2417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/generation/utils.py:854\u001b[39m, in \u001b[36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[39m\u001b[34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[39m\n\u001b[32m    852\u001b[39m encoder_kwargs[\u001b[33m\"\u001b[39m\u001b[33mreturn_dict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    853\u001b[39m encoder_kwargs[model_input_name] = inputs_tensor\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m]: ModelOutput = \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    856\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:1124\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1107\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m   1108\u001b[39m         layer_module.forward,\n\u001b[32m   1109\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1121\u001b[39m         cache_position,\n\u001b[32m   1122\u001b[39m     )\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[32m   1142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:679\u001b[39m, in \u001b[36mT5Block.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    664\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    665\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    677\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    678\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m     hidden_states, past_key_value = self_attention_outputs[:\u001b[32m2\u001b[39m]\n\u001b[32m    690\u001b[39m     attention_outputs = self_attention_outputs[\u001b[32m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:597\u001b[39m, in \u001b[36mT5LayerSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    586\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    587\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    594\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    595\u001b[39m ):\n\u001b[32m    596\u001b[39m     normed_hidden_states = \u001b[38;5;28mself\u001b[39m.layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m     attention_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m     hidden_states = hidden_states + \u001b[38;5;28mself\u001b[39m.dropout(attention_output[\u001b[32m0\u001b[39m])\n\u001b[32m    608\u001b[39m     outputs = (hidden_states,) + attention_output[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:556\u001b[39m, in \u001b[36mT5Attention.forward\u001b[39m\u001b[34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    553\u001b[39m scores += position_bias_masked\n\u001b[32m    555\u001b[39m \u001b[38;5;66;03m# (batch_size, n_heads, seq_length, key_length)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m attn_weights = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.type_as(scores)\n\u001b[32m    557\u001b[39m attn_weights = nn.functional.dropout(attn_weights, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/functional.py:2140\u001b[39m, in \u001b[36msoftmax\u001b[39m\u001b[34m(input, dim, _stacklevel, dtype)\u001b[39m\n\u001b[32m   2138\u001b[39m     dim = _get_softmax_dim(\u001b[33m\"\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m.dim(), _stacklevel)\n\u001b[32m   2139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2140\u001b[39m     ret = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2141\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2142\u001b[39m     ret = \u001b[38;5;28minput\u001b[39m.softmax(dim, dtype=dtype)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df_small = df.head(10).copy()\n",
    "\n",
    "# Apply corrections row-wise on df_small only\n",
    "df_small['corrected_text'] = df_small[TEXT_COL].fillna('').apply(correct_text)\n",
    "\n",
    "# Attach corrected column back or use df_small directly for saving\n",
    "df['corrected_text'] = corrected_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved corrected DataFrame with 104236 rows to /Users/marencordts/Desktop/Semantic_Data_Stories/course-data-stories/merged_all_added_corrected.pkl\n"
     ]
    }
   ],
   "source": [
    "# 5. Save results\n",
    "out_path = '/Users/marencordts/Desktop/Semantic_Data_Stories/course-data-stories/merged_all_added_corrected.pkl'\n",
    "with open(out_path, 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "print(f\"Saved corrected DataFrame with {len(df)} rows to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 5. Save small results only\n",
    "test_file = '/Users/marencordts/Desktop/Semantic_Data_Stories/course-data-stories/merged_all_added_corrected_3.pkl'\n",
    "with open(test_file, 'wb') as f:\n",
    "    pickle.dump(small, f)\n",
    "print(f\"Saved 3 corrected articles to {test_file}\")\n",
    "\n",
    "# Quick display of test subset\n",
    "for idx, row in small.iterrows():\n",
    "    print(f\"--- Entry {idx} ---\")\n",
    "    print(\"Original:\", row[TEXT_COL][:200].replace('',' '))\n",
    "    print(\"Corrected:\", row['corrected_text'][:200].replace('',' '))\n",
    "    print()\n",
    "\n",
    "# 6. Load and inspect full corrected data\n",
    "print(\"Loading full corrected dataset...\")\n",
    "with open('/Users/maren/Desktop/Semantic_Data_Stories/course-data-stories/merged_all_added_corrected.pkl', 'rb') as f:\n",
    "    corrected_full = pickle.load(f)\n",
    "\n",
    "if isinstance(corrected_full, pd.DataFrame):\n",
    "    print(\"Corrected DataFrame shape:\", corrected_full.shape)\n",
    "    print(corrected_full[['page_id', TEXT_COL, 'corrected_text']].head(3))\n",
    "else:\n",
    "    print(\"Loaded list of items. Showing first 3 entries:\")\n",
    "    for item in corrected_full[:3]:\n",
    "        if isinstance(item, dict):\n",
    "            print({k: item[k] for k in ['page_id', TEXT_COL, 'corrected_text'] if k in item})\n",
    "        else:\n",
    "            print(item[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Invalid buffer size: 50.86 GB",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df.iterrows():\n\u001b[32m      4\u001b[39m     raw = row[TEXT_COL] \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     corrected_texts.append(\u001b[43mcorrect_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mcorrect_text\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     15\u001b[39m     prompt = (\n\u001b[32m     16\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKorrigiere das falsch erkannte Wort \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtok\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m im deutschen Satz: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGib nur das Ersatzwort zurück.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     out = \u001b[43mcorrector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     replacement = out[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m).strip() \u001b[38;5;129;01mor\u001b[39;00m tok\n\u001b[32m     21\u001b[39m     correction_cache[tok] = replacement\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/pipelines/text2text_generation.py:186\u001b[39m, in \u001b[36mText2TextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    158\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[32m    160\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    183\u001b[39m \u001b[33;03m          ids of the generated text.\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    188\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m    189\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[32m0\u001b[39m])\n\u001b[32m    190\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[32m    191\u001b[39m     ):\n\u001b[32m    192\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/pipelines/base.py:1431\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1424\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1425\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1428\u001b[39m         )\n\u001b[32m   1429\u001b[39m     )\n\u001b[32m   1430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/pipelines/base.py:1438\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1436\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1437\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1438\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1439\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/pipelines/base.py:1338\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1336\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1337\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/pipelines/text2text_generation.py:215\u001b[39m, in \u001b[36mText2TextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    213\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m output_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m out_b = output_ids.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/generation/utils.py:2412\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2408\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`attention_mask` passed to `generate` must be 2D.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[32m   2411\u001b[39m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2412\u001b[39m     model_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[32m   2417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/generation/utils.py:854\u001b[39m, in \u001b[36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[39m\u001b[34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[39m\n\u001b[32m    852\u001b[39m encoder_kwargs[\u001b[33m\"\u001b[39m\u001b[33mreturn_dict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    853\u001b[39m encoder_kwargs[model_input_name] = inputs_tensor\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m]: ModelOutput = \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    856\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:1124\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1107\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m   1108\u001b[39m         layer_module.forward,\n\u001b[32m   1109\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1121\u001b[39m         cache_position,\n\u001b[32m   1122\u001b[39m     )\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[32m   1142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:679\u001b[39m, in \u001b[36mT5Block.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    664\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    665\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    677\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    678\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m     hidden_states, past_key_value = self_attention_outputs[:\u001b[32m2\u001b[39m]\n\u001b[32m    690\u001b[39m     attention_outputs = self_attention_outputs[\u001b[32m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:597\u001b[39m, in \u001b[36mT5LayerSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    586\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    587\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    594\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    595\u001b[39m ):\n\u001b[32m    596\u001b[39m     normed_hidden_states = \u001b[38;5;28mself\u001b[39m.layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m     attention_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m     hidden_states = hidden_states + \u001b[38;5;28mself\u001b[39m.dropout(attention_output[\u001b[32m0\u001b[39m])\n\u001b[32m    608\u001b[39m     outputs = (hidden_states,) + attention_output[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:524\u001b[39m, in \u001b[36mT5Attention.forward\u001b[39m\u001b[34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    521\u001b[39m             past_key_value.is_updated[\u001b[38;5;28mself\u001b[39m.layer_idx] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    523\u001b[39m \u001b[38;5;66;03m# compute scores, equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m scores = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m position_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    527\u001b[39m     key_length = key_states.shape[-\u001b[32m2\u001b[39m]\n",
      "\u001b[31mRuntimeError\u001b[39m: Invalid buffer size: 50.86 GB"
     ]
    }
   ],
   "source": [
    "# 4. Apply corrections row-wise\n",
    "corrected_texts = []\n",
    "for _, row in df.iterrows():\n",
    "    raw = row[TEXT_COL] or ''\n",
    "    corrected_texts.append(correct_text(raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample before/after for first 5 items:\n",
      "--- Item 0 ---\n",
      "'Page-ID' im deutschen Satz 'Page-ID' gibt nur das Ersatzwort zurück.\n",
      "--- Item 1 ---\n",
      "pagenumber\n",
      "--- Item 2 ---\n",
      "'Publication-Date' im deutschen Satz 'publication-date' gibt nur das Ersatzwort zurück.\n",
      "--- Item 3 ---\n",
      "Place-of-Distribution' im deutschen Satz 'Place-of-Distribution' gibt nur das Ersatzwort zurück.\n",
      "--- Item 4 ---\n",
      "language\n"
     ]
    }
   ],
   "source": [
    "# Quick check: print before/after for first 5 rows\n",
    "for idx in range(min(5, len(df))):\n",
    "    print(f\"--- Row {idx} ---\")\n",
    "    print(\"Original:\\n\", df.at[idx, TEXT_COL][:200])\n",
    "    print(\"Corrected:\\n\", df.at[idx, 'corrected_text'][:200])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Compare first few\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     raw  = raw_articles[i] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mraw_articles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m raw_articles[i].get(\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     17\u001b[39m     corr = corr_articles[i] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(corr_articles[i], \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m corr_articles[i].get(\u001b[33m'\u001b[39m\u001b[33mcorrected_text\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Article \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Semantic_Data_Stories/course-data-stories/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Paths\n",
    "raw_path      = '/Users/marencordts/Desktop/Semantic_Data_Stories/course-data-stories/merged_all_added.pkl'\n",
    "corrected_path = '/Users/marencordts/Desktop/Semantic_Data_Stories/course-data-stories/merged_all_added_corrected.pkl'\n",
    "\n",
    "# Load\n",
    "with open(raw_path, 'rb') as f:\n",
    "    raw_articles = pickle.load(f)\n",
    "\n",
    "with open(corrected_path, 'rb') as f:\n",
    "    corr_articles = pickle.load(f)\n",
    "\n",
    "# Compare first few\n",
    "for i in range(5):\n",
    "    raw  = raw_articles[i] if isinstance(raw_articles[i], str) else raw_articles[i].get('text', '')\n",
    "    corr = corr_articles[i] if isinstance(corr_articles[i], str) else corr_articles[i].get('corrected_text', '')\n",
    "    print(f\"--- Article {i} ---\")\n",
    "    print(\"RAW      :\", raw[:200].replace('\\n',' '))\n",
    "    print(\"CORRECTED:\", corr[:200].replace('\\n',' '))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
